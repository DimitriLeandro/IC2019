{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para gravar o SESA com o ReSpeaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que a acurácia do sistema em tempo real seja maior, vamos treinar o classificador com áudios gravados pelo próprio respeaker, assim, a etapa de teste ficará semelhante à de treinamento.\n",
    "\n",
    "Vou analisar o tamanho do SESA_v2_16_kHz_16 bits e mandar o respeaker gravar um áudio grandão com esse tamanho. Depois disso eu mando esse áudio pro PC e separo o que é sirene, tiro, explosão e casual manualmente. Desse áudio grandão com o dataset inteiro dentro, vou separa-lo em 4. Um áudio com todos os sons de tiro, um com todos os sons de explosões, e assim por diante. O janelamento será feito posteriormente pela extração de features, e não importa muito se a gnt vai perder a informação de qual é o áudio original. \n",
    "\n",
    "Explicando melhor: na abordagem anterior, o CSV ficava com n janelas do áudio siren_034.wav, m janelas do áudio siren_035.wav e assim por diante. A partir de agora, ele vai ter muuuitas janelas de um mesmo arquivo, o siren_000.wav, pois esse novo arquivo siren_000.wav vai conter dentro dele todos os outros arquivos de sirene, como os próprios siren_034.wav e siren_035.wav.\n",
    "\n",
    "O algoritmo desse jupyter pode ser rodado toda vez que o dataset for ser gravado COM O RESPEAKER. Uma abordagem de data augmentation pode envolver gravar o dataset inteiro com alto falantes diferentes, com a raspberry posicionada em lugares diferentes e tal... Tem que ver.\n",
    "\n",
    "E vamos gravar já com os áudios sem silêncio. No PC os arquivos WAV já passaram por um processo de remoção de silêncio.\n",
    "\n",
    "Pra fazer a gravação eu vou colocar os áudios no meu PC msm, mandar pra um alto falante top e ai é só conectar esse jupyter aqui pela raspberry e rodar ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/.pyenv/versions/3.6.1/envs/venv1/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando o ID do dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listarDispositivos():\n",
    "    p = pyaudio.PyAudio()\n",
    "    info = p.get_host_api_info_by_index(0)\n",
    "    numdevices = info.get('deviceCount')\n",
    "\n",
    "    for i in range(0, numdevices):\n",
    "            if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "                print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  seeed-4mic-voicecard: bcm2835-i2s-ac10x-codec0 ac10x-codec.1-003b-0 (hw:1,0)\n",
      "Input Device id  3  -  ac108\n"
     ]
    }
   ],
   "source": [
    "listarDispositivos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo de gravação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Só pra gnt ver qual é o tempo que tenho que deixar o respeaker gravando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de cada pasta (s): [565.6964375, 596.5214375000002, 544.7881874999999, 573.3851250000002, 543.7693124999998]\n",
      "Tempo de cada pasta (m): [9.42827396 9.94202396 9.07980312 9.55641875 9.06282187]\n"
     ]
    }
   ],
   "source": [
    "caminhoArquivosWAV = \"/home/pi/Datasets/SESA_v2_16kHz_16bits/original/\"\n",
    "\n",
    "tempoCadaPasta = []\n",
    "\n",
    "for pastaAtual in range(1,6):\n",
    "    \n",
    "    caminhoPastaAtual    = caminhoArquivosWAV+\"fold_\"+str(pastaAtual)+\"/\" \n",
    "    tempoTotalPastaAtual = 0\n",
    "\n",
    "    for audioAtual in os.listdir(caminhoPastaAtual):\n",
    "        tempoTotalPastaAtual += librosa.get_duration(filename=caminhoPastaAtual+audioAtual)\n",
    "        \n",
    "    tempoCadaPasta.append(tempoTotalPastaAtual)\n",
    "    \n",
    "print(\"Tempo de cada pasta (s):\", tempoCadaPasta)\n",
    "print(\"Tempo de cada pasta (m):\", np.array(tempoCadaPasta)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gravando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PARAMETROS INICIAIS \n",
    "respeakerIndex          = 0\n",
    "respeakerFreqAmostragem = 16000\n",
    "respeakerProfundidade   = 2\n",
    "respeakerCanais         = 1\n",
    "tempoGravacaoSegundos   = 630\n",
    "nomeArquivoWAVSaida     = \"/home/pi/GravacoesReSpeaker/gravacaoSESAReSpeaker_\"+str(int(respeakerFreqAmostragem))+\"hz_\"+str(int(respeakerProfundidade*8))+\"bits\"+str(time())+\".wav\"\n",
    "    \n",
    "# INSTANCIANDO UM OBJ PY AUDIO E MANDANDO OS PARAMETROS INICIAIS\n",
    "objPyAudio = pyaudio.PyAudio()\n",
    "stream = objPyAudio.open(\n",
    "    input_device_index = respeakerIndex,\n",
    "    rate               = respeakerFreqAmostragem,\n",
    "    format             = objPyAudio.get_format_from_width(respeakerProfundidade),\n",
    "    channels           = respeakerCanais,\n",
    "    input=True    \n",
    ")\n",
    " \n",
    "# GRANVANDO\n",
    "print(\"INICIANDO A GRAVAÇÃO\")\n",
    "gravacaoBinario = stream.read(tempoGravacaoSegundos * respeakerFreqAmostragem)    \n",
    "print(\"GRAVAÇÃO FINALIZADA\")\n",
    " \n",
    "# MATANDO OS OBJETOS PRA LIMPAR MEMORIA\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "objPyAudio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALVANDO O ARQUIVO WAV POIS O ARRAY JANELAS E BINARIO, NAO DA PRA OUVIR DIRETO DELE\n",
    "wf = wave.open(nomeArquivoWAVSaida, 'wb')\n",
    "wf.setnchannels(respeakerCanais)\n",
    "wf.setsampwidth(objPyAudio.get_sample_size(objPyAudio.get_format_from_width(respeakerProfundidade)))\n",
    "wf.setframerate(respeakerFreqAmostragem)\n",
    "wf.writeframes(b''.join([gravacaoBinario]))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUVINDO\n",
    "sinal, freqAmostragem = librosa.load(nomeArquivoWAVSaida, sr=None, mono=False)\n",
    "print(sinal.shape)\n",
    "print(freqAmostragem)\n",
    "Audio(data=sinal, rate=freqAmostragem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
