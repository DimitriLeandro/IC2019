{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para fazer o Grid Search com alguns classificadores para o SESA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoArquivo = \"/home/dimi/Programming/IC2019/ML/jupyter/Outros/resultadosGridsearchSESA.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados(modelo, caminhoArquivo):\n",
    "    \n",
    "    mediaAcuracia   = modelo.best_score_\n",
    "    desvPadAcuracia = np.std(modelo.cv_results_['mean_test_score'])\n",
    "    mediaTempo      = np.mean(modelo.cv_results_['mean_score_time'])\n",
    "    desvPadTempo    = np.std(modelo.cv_results_['mean_score_time'])\n",
    "    \n",
    "    objFile = open(caminhoArquivo, \"a\")\n",
    "    \n",
    "    linha = str(modelo.best_estimator_) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Acurácia Média: ' + str(mediaAcuracia) + ' +- ' + str(desvPadAcuracia) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Time: ' + str(mediaTempo) + ' +- ' + str(desvPadTempo) + \"\\n\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)   \n",
    "    \n",
    "    objFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abrindo os CSVs de treino e teste e separando os dados em x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dataframe treino: 5988\n",
      "Tamanho dataframe teste: 1354\n",
      "Total de dados: 7342\n"
     ]
    }
   ],
   "source": [
    "caminhoCSVTreino = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train/treino_normalizado_semPCA.csv\"\n",
    "caminhoCSVTeste  = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/teste_normalizado_semPCA.csv\"\n",
    "\n",
    "dataframeTreino  = pd.read_csv(caminhoCSVTreino)\n",
    "dataframeTeste   = pd.read_csv(caminhoCSVTeste)\n",
    "\n",
    "print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Só rodar a célula abaixo se quiser diminuir o tamanho do dataset para testes rápidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dataframe treino: 1497\n",
      "Tamanho dataframe teste: 338\n",
      "Total de dados: 1835\n"
     ]
    }
   ],
   "source": [
    "# percentual = 0.25\n",
    "\n",
    "# dataframeTreino = dataframeTreino[0:int(percentual * len(dataframeTreino))]\n",
    "# dataframeTeste  = dataframeTeste[0:int(percentual * len(dataframeTeste))]\n",
    "\n",
    "# print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "# print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "# print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando o Group K Fold para garantir que todos os frames de um mesmo áudio fiquem na mesma pasta em um K Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a validação cruzada, não posso deixar que um mesmo áudio seja usado tanto no treinamento quanto no teste. É preciso garantir que todos os frames de um determinado áudio façam parte ou do treinamento ou do teste.\n",
    "\n",
    "Fazendo \"groups\" ser igual ao nomes dos arquivos, é possível usar a classe GroupKFold para fazer o K Fold sem que os áudios se misturem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = np.array(dataframeTreino.iloc[:,1:-1].values.tolist() + dataframeTeste.iloc[:,1:-1].values.tolist())\n",
    "target = np.array(dataframeTreino.iloc[:,-1].values.tolist() + dataframeTeste.iloc[:,-1].values.tolist())\n",
    "groups = np.array(dataframeTreino.iloc[:,0].values.tolist() + dataframeTeste.iloc[:,0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.7859477124183006\n",
      "Acurácia: 0.7369281045751634\n",
      "Acurácia: 0.6890343698854338\n"
     ]
    }
   ],
   "source": [
    "# TESTANDO COMO USAR ESSA CLASSE\n",
    "# objGroupKFold = GroupKFold(n_splits=3)\n",
    "\n",
    "# for trainIndex, testIndex in objGroupKFold.split(data, target, groups):\n",
    "#     xTrain, xTest = data[trainIndex], data[testIndex]\n",
    "#     yTrain, yTest = target[trainIndex], target[testIndex]\n",
    "    \n",
    "#     objKNN = KNeighborsClassifier()\n",
    "#     objKNN.fit(xTrain, yTrain)\n",
    "#     yPred = objKNN.predict(xTest)\n",
    "    \n",
    "#     print(\"Acurácia:\", accuracy_score(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_knn = [\n",
    "    {\n",
    "        'n_neighbors': [3,5,7,11,13],\n",
    "     \n",
    "        'weights': ['uniform', \n",
    "                    'distance'],\n",
    "     \n",
    "        'metric': ['euclidean', \n",
    "                   'manhattan', \n",
    "                   'chebyshev', \n",
    "                   'minkowski']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params_knn,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46f350a98>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'chebyshev',\n",
       "                                     'minkowski'],\n",
       "                          'n_neighbors': [3, 5, 7, 11, 13, 17],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "                     weights='distance') \n",
      "\n",
      "0.8703350585671479\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_knn, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_sgd = [\n",
    "    {\n",
    "        'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001],\n",
    "        'tol': [0.01, 0.001, 0.0001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_sgd = GridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    grid_params_sgd,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46f325a98>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     r...0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 0.0001, 0.001],\n",
       "                          'loss': ['hinge', 'log', 'modified_huber',\n",
       "                                   'squared_hinge', 'perceptron'],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "\n",
      "0.8387360392263689\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_sgd, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_tree = [\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [2,6,10,16],\n",
    "        'min_samples_leaf': [1,2,3,4,5],\n",
    "        'min_impurity_split': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid_params_tree,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f0bcc4ec228>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_impurity_split': [1e-08, 1e-07, 1e-06],\n",
       "                          'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                          'min_samples_split': [2, 6, 10, 16]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tree.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=1e-08,\n",
      "                       min_samples_leaf=4, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n",
      "Acurácia Média: 0.7209809264305177 +- 0.0069662224790465336\n",
      "\n",
      "Time: 0.0012383778889973958 +- 0.00046300543229965604\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_tree, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_svm = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'degree': [3,4,5],\n",
    "        'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    SVC(),\n",
    "    grid_params_svm,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   20.7s finished\n",
      "/home/dimi/venvIC/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f0bcb62df48>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1],\n",
       "                          'decision_function_shape': ['ovo', 'ovr'],\n",
       "                          'degree': [3, 4, 5],\n",
       "                          'kernel': ['linear', 'poly', 'rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False) \n",
      "\n",
      "0.8332425068119891\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_svm, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_perceptron = [\n",
    "    {\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'tol': [0.01, 0.001, 0.0001, 0.00001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_perceptron = GridSearchCV(\n",
    "    Perceptron(),\n",
    "    grid_params_perceptron,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1256s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f0bcc6a64f8>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
       "                                  early_stopping=False, eta0=1.0,\n",
       "                                  fit_intercept=True, max_iter=1000,\n",
       "                                  n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "                                  random_state=0, shuffle=True, tol=0.001,\n",
       "                                  validation_fraction=0.1, verbose=0,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 1e-05, 0.0001, 0.001, 0.01],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_perceptron.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty='l2', random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "\n",
      "0.7743869209809264\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_perceptron, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_lda = [\n",
    "    {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'store_covariance': [True, False],\n",
    "        'tol': [1e-5,1e-4,1e-3]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_lda = GridSearchCV(\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    grid_params_lda,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7f0bcbc4d4f8>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                  priors=None, shrinkage=None,\n",
       "                                                  solver='svd',\n",
       "                                                  store_covariance=False,\n",
       "                                                  tol=0.0001),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'solver': ['svd', 'lsqr', 'eigen'],\n",
       "                          'store_covariance': [True, False],\n",
       "                          'tol': [1e-05, 0.0001, 0.001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lda.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=True, tol=1e-05)\n",
      "\n",
      "Acurácia Média: 0.7449591280653951 +- 1.1102230246251565e-16\n",
      "Time: 0.005261160709239818 +- 0.002963386762856438\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_lda, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
