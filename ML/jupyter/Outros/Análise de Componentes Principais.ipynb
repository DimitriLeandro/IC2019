{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Componentes Principais "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXPERIMENTO I:\n",
    "    PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET ORIGINAL E O TESTE COM O DATASET ORIGINAL\n",
    "\n",
    "##### EXEPRIMENTO II:\n",
    "    PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET COMPLETO E O TESTE COM O DATASET ORIGINAL\n",
    "\n",
    "##### EXEPRIMENTO III:\n",
    "    PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET ORIGINAL E O TESTE COM O DATASET COMPLETO\n",
    "\n",
    "##### EXEPRIMENTO IV:\n",
    "    PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET COMPLETO E O TESTE COM O DATASET COMPLETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFININDO ALGUNS PARÂMETROS DO GRÁFICO\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "params = {\n",
    "    'figure.figsize': [11, 5.5], \n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize':20, \n",
    "    'font.size': 18,\n",
    "    'legend.fontsize': 14, \n",
    "    'xtick.labelsize': 12, \n",
    "    'ytick.labelsize': 12,\n",
    "    'axes.axisbelow': True\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoCSVTreinamentoCompleto = \"/home/dimi/Programming/MachineLearningUFABC/Projeto_Final/datasets/500ms_60_features/dataset_treinamento_completo.csv\"\n",
    "caminhoCSVTesteCompleto       = \"/home/dimi/Programming/MachineLearningUFABC/Projeto_Final/datasets/500ms_60_features/dataset_teste_completo.csv\"\n",
    "\n",
    "arrayClassificadores = [\"KNN\", \"SVM\", \"MLP\", \"RF\", \"LDA\"]\n",
    "caminhoOndeSalvar = \"resultados/\"\n",
    "\n",
    "resultadosRapidos = False # REDUZ O DATASET A 0.30 CASO TRUE (COLOCAR TRUE APENAS PARA TESTES RAPIDOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deletando qualquer resultado anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(caminhoOndeSalvar+\"PCA/\") == True:\n",
    "    shutil.rmtree(caminhoOndeSalvar+\"PCA/\")\n",
    "    \n",
    "os.makedirs(caminhoOndeSalvar+\"PCA/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustarDataset(dataframe, efeitosDesejados):\n",
    "    \n",
    "    if not efeitosDesejados in [\"original\", \"original+ruido\", \"original+pitch\", \"original+tempo\", \"original+velocidade\", \"completo\"]:\n",
    "        print(\"Escolha dentre os seguintes efeitos: original, original+ruido, original+pitch, original+tempo, original+velocidade ou completo!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    else:\n",
    "        if efeitosDesejados == \"original\":\n",
    "            dataframeAjustado = dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)]\n",
    "        elif efeitosDesejados == \"original+ruido\":\n",
    "            dataframeAjustado = pd.concat([dataframe.loc[(dataframe['ruido']==1)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)], dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)]], ignore_index=True)\n",
    "        elif efeitosDesejados == \"original+pitch\":\n",
    "            dataframeAjustado = pd.concat([dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==1)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)], dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)]], ignore_index=True)\n",
    "        elif efeitosDesejados == \"original+tempo\":\n",
    "            dataframeAjustado = pd.concat([dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==1)&(dataframe['velocidade']==0)], dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)]], ignore_index=True)\n",
    "        elif efeitosDesejados == \"original+velocidade\":\n",
    "            dataframeAjustado = pd.concat([dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==1)], dataframe.loc[(dataframe['ruido']==0)&(dataframe['pitch']==0)&(dataframe['tempo']==0)&(dataframe['velocidade']==0)]], ignore_index=True)\n",
    "        else:\n",
    "            dataframeAjustado = dataframe\n",
    "            \n",
    "        # SEPARO O QUE E O QUE\n",
    "        data   = dataframeAjustado.iloc[:, 5:-1].to_numpy()\n",
    "        target = dataframeAjustado.iloc[:, -1].to_numpy()\n",
    "        \n",
    "        del dataframeAjustado\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarPCA(xTrain, xTest, qtdDimensoes):\n",
    "    \n",
    "    objPCA = PCA(n_components=qtdDimensoes).fit(xTrain)\n",
    "    xTrainPCA = objPCA.transform(xTrain)\n",
    "    xTestPCA  = objPCA.transform(xTest)\n",
    "    \n",
    "    del objPCA\n",
    "    return xTrainPCA, xTestPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarEClassificar(xTrain, xTest, yTrain, yTest, classificador):\n",
    "    \n",
    "    if classificador == \"KNN\":\n",
    "        objClassificador = KNeighborsClassifier(n_neighbors=1)\n",
    "    elif classificador == \"LDA\":\n",
    "        objClassificador = LinearDiscriminantAnalysis()\n",
    "    elif classificador == \"RF\":\n",
    "        objClassificador = RandomForestClassifier(n_estimators=10)\n",
    "    elif classificador == \"SVM\":\n",
    "        objClassificador = SVC(gamma=\"scale\")\n",
    "    else:\n",
    "        objClassificador = MLPClassifier(hidden_layer_sizes=())\n",
    "    \n",
    "    objClassificador.fit(xTrain, yTrain)\n",
    "    yPred = objClassificador.predict(xTest)\n",
    "    \n",
    "    del objClassificador\n",
    "    return accuracy_score(yTest, yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvarArrayAcuraciaCadaDimensao(arrayAcuraciaCadaDimensao, acuraciaReferencial, experimento, classificador, caminhoOndeSalvar):\n",
    "    \n",
    "    # ABRINDO O ARQUIVO TXT\n",
    "    objFile = open(caminhoOndeSalvar+\"PCA/resultados_PCA.txt\", \"a\")\n",
    "\n",
    "    # ESCREVENDO O CABECALHO\n",
    "    objFile.write(\"EXPERIMENTO \" + str(experimento) + \" - \" + classificador + \":\\n\")\n",
    "    \n",
    "    # ESCREVENDO A ACURACIA SEM PCA (REFERENCIAL)\n",
    "    objFile.write(\"Acurácia referencial (sem PCA): \" + str(acuraciaReferencial) + \"\\n\")\n",
    "\n",
    "    # ESCREVENDO O RESULTADO DE CADA DIMENSAO\n",
    "    objFile.write(\"Acurácia com PCA para cada dimensionalidade: \")\n",
    "    for acuraciaAtual in arrayAcuraciaCadaDimensao:\n",
    "        objFile.write(str(acuraciaAtual) + \", \")\n",
    "    objFile.write(\"\\n\\n\")\n",
    "\n",
    "    # FECHANDO\n",
    "    objFile.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printarGrafico(arrayAcuraciaCadaDimensao, acuraciaReferencial, experimento, classificador, caminhoOndeSalvar):\n",
    "    \n",
    "    plt.plot(np.arange(1,len(arrayAcuraciaCadaDimensao)+1), np.full(len(arrayAcuraciaCadaDimensao), acuraciaReferencial), \"--\", color=\"black\", label=\"Referencial (sem PCA)\")\n",
    "    plt.plot(np.arange(1,len(arrayAcuraciaCadaDimensao)+1), arrayAcuraciaCadaDimensao, label=\"PCA\")\n",
    "    plt.title(\"EXPERIMENTO \" + str(experimento) + \" - \" + classificador)\n",
    "    plt.xlabel(\"Qtd de Dimensões\")\n",
    "    plt.ylabel(\"Acurácia\")\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.savefig(caminhoOndeSalvar+\"PCA/experimento\"+str(experimento)+\"_\"+classificador+\".pdf\", format='pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarPCA(classificador, qtdDimensoes, xTrain, xTest, yTrain, yTest):\n",
    "    # APLICO O PCA\n",
    "    objPCA    = PCA(n_components=qtdDimensoes).fit(xTrain)\n",
    "    xTrainPCA = objPCA.transform(xTrain)\n",
    "    xTestPCA  = objPCA.transform(xTest)\n",
    "\n",
    "    # CALCULO A ACURACIA COM A REDUCAO\n",
    "    return treinarEClassificar(xTrainPCA, xTestPCA, yTrain, yTest, classificador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testarUmClassificador(experimento, classificador, xTrain, xTest, yTrain, yTest, caminhoOndeSalvar):\n",
    "    print(\"Iniciando os testes com o classificador\", classificador)\n",
    "    \n",
    "    # OBTENDO A ACURACIA REFERENCIAL (SEM PCA)\n",
    "    acuraciaReferencial = treinarEClassificar(xTrain, xTest, yTrain, yTest, classificador)\n",
    "    # ITERANDO AS DIMENSOES DO PCA\n",
    "    arrayAcuraciaCadaDimensao = Parallel(n_jobs=-1, verbose=10)(delayed(aplicarPCA)(classificador, qtdDimensoesAtual, xTrain, xTest, yTrain, yTest) for qtdDimensoesAtual in range(1, len(xTest[0])))\n",
    "    \n",
    "    # NESSE PONTO EU JA VOU TER O RESULTADO FINAL PARA O CLASSIFICADOR ATUAL NO EXPERIMENTO ATUAL, VOU SALVAR AS INFORMACOES\n",
    "    salvarArrayAcuraciaCadaDimensao(arrayAcuraciaCadaDimensao, acuraciaReferencial, experimento, classificador, caminhoOndeSalvar)\n",
    "    printarGrafico(arrayAcuraciaCadaDimensao, acuraciaReferencial, experimento, classificador, caminhoOndeSalvar)\n",
    "    \n",
    "    print(\"Todos os testes com o classificador\", classificador, \"foram finalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENTO I:\n",
    "PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET ORIGINAL E O TESTE COM O DATASET ORIGINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentoAtual  = 1\n",
    "efeitoTreinamento = \"original\"\n",
    "efeitoTeste       = \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreinamento  = pd.read_csv(caminhoCSVTreinamentoCompleto)\n",
    "dfTeste        = pd.read_csv(caminhoCSVTesteCompleto)\n",
    "xTrain, yTrain = ajustarDataset(dfTreinamento, efeitoTreinamento)\n",
    "xTest, yTest   = ajustarDataset(dfTeste, efeitoTeste)\n",
    "del dfTreinamento\n",
    "del dfTeste\n",
    "\n",
    "if resultadosRapidos == True:\n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain) # TESTES RAPIDOS\n",
    "    xTest, yTest   = shuffle(xTest, yTest) # TESTES RAPIDOS\n",
    "    xTrain = xTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTrain = yTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    xTest  = xTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTest  = yTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "\n",
    "# RODANDO A ANALISE PARA CADA CLASSIFICADOR\n",
    "Parallel(n_jobs=-1, verbose=10)(delayed(testarUmClassificador)(experimentoAtual, classificadorAtual, xTrain, xTest, yTrain, yTest, caminhoOndeSalvar) for classificadorAtual in arrayClassificadores)\n",
    "    \n",
    "# LIMPO A MEMORIA\n",
    "del xTrain\n",
    "del xTest\n",
    "del yTrain\n",
    "del yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXEPRIMENTO II:\n",
    "PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET COMPLETO E O TESTE COM O DATASET ORIGINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentoAtual  = 2\n",
    "efeitoTreinamento = \"completo\"\n",
    "efeitoTeste       = \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreinamento  = pd.read_csv(caminhoCSVTreinamentoCompleto)\n",
    "dfTeste        = pd.read_csv(caminhoCSVTesteCompleto)\n",
    "xTrain, yTrain = ajustarDataset(dfTreinamento, efeitoTreinamento)\n",
    "xTest, yTest   = ajustarDataset(dfTeste, efeitoTeste)\n",
    "del dfTreinamento\n",
    "del dfTeste\n",
    "\n",
    "if resultadosRapidos == True:\n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain) # TESTES RAPIDOS\n",
    "    xTest, yTest   = shuffle(xTest, yTest) # TESTES RAPIDOS\n",
    "    xTrain = xTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTrain = yTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    xTest  = xTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTest  = yTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "\n",
    "# RODANDO A ANALISE PARA CADA CLASSIFICADOR\n",
    "Parallel(n_jobs=-1, verbose=10)(delayed(testarUmClassificador)(experimentoAtual, classificadorAtual, xTrain, xTest, yTrain, yTest, caminhoOndeSalvar) for classificadorAtual in arrayClassificadores)\n",
    "    \n",
    "# LIMPO A MEMORIA\n",
    "del xTrain\n",
    "del xTest\n",
    "del yTrain\n",
    "del yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXEPRIMENTO III:\n",
    "PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET ORIGINAL E O TESTE COM O DATASET COMPLETO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentoAtual  = 3\n",
    "efeitoTreinamento = \"original\"\n",
    "efeitoTeste       = \"completo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreinamento  = pd.read_csv(caminhoCSVTreinamentoCompleto)\n",
    "dfTeste        = pd.read_csv(caminhoCSVTesteCompleto)\n",
    "xTrain, yTrain = ajustarDataset(dfTreinamento, efeitoTreinamento)\n",
    "xTest, yTest   = ajustarDataset(dfTeste, efeitoTeste)\n",
    "del dfTreinamento\n",
    "del dfTeste\n",
    "\n",
    "if resultadosRapidos == True:\n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain) # TESTES RAPIDOS\n",
    "    xTest, yTest   = shuffle(xTest, yTest) # TESTES RAPIDOS\n",
    "    xTrain = xTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTrain = yTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    xTest  = xTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTest  = yTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "\n",
    "# RODANDO A ANALISE PARA CADA CLASSIFICADOR\n",
    "Parallel(n_jobs=-1, verbose=10)(delayed(testarUmClassificador)(experimentoAtual, classificadorAtual, xTrain, xTest, yTrain, yTest, caminhoOndeSalvar) for classificadorAtual in arrayClassificadores)\n",
    "    \n",
    "# LIMPO A MEMORIA\n",
    "del xTrain\n",
    "del xTest\n",
    "del yTrain\n",
    "del yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXEPRIMENTO IV:\n",
    "PCA PARA OS 5 CLASSIFICADORES ONDE O TREINAMENTO É FEITO COM O DATASET COMPLETO E O TESTE COM O DATASET COMPLETO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentoAtual  = 4\n",
    "efeitoTreinamento = \"completo\"\n",
    "efeitoTeste       = \"completo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTreinamento  = pd.read_csv(caminhoCSVTreinamentoCompleto)\n",
    "dfTeste        = pd.read_csv(caminhoCSVTesteCompleto)\n",
    "xTrain, yTrain = ajustarDataset(dfTreinamento, efeitoTreinamento)\n",
    "xTest, yTest   = ajustarDataset(dfTeste, efeitoTeste)\n",
    "del dfTreinamento\n",
    "del dfTeste\n",
    "\n",
    "if resultadosRapidos == True:\n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain) # TESTES RAPIDOS\n",
    "    xTest, yTest   = shuffle(xTest, yTest) # TESTES RAPIDOS\n",
    "    xTrain = xTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTrain = yTrain[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    xTest  = xTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "    yTest  = yTest[:int(0.3*len(yTest))] # TESTES RAPIDOS\n",
    "\n",
    "# RODANDO A ANALISE PARA CADA CLASSIFICADOR\n",
    "Parallel(n_jobs=-1, verbose=10)(delayed(testarUmClassificador)(experimentoAtual, classificadorAtual, xTrain, xTest, yTrain, yTest, caminhoOndeSalvar) for classificadorAtual in arrayClassificadores)\n",
    "    \n",
    "# LIMPO A MEMORIA\n",
    "del xTrain\n",
    "del xTest\n",
    "del yTrain\n",
    "del yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
