{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para fazer o Grid Search com alguns classificadores para o SESA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoArquivo = \"/home/dimi/Programming/IC2019/ML/jupyter/Outros/resultadosGridsearchSESAAugmentation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados(modelo, caminhoArquivo):\n",
    "    \n",
    "    mediaAcuracia   = modelo.best_score_\n",
    "    desvPadAcuracia = np.std(modelo.cv_results_['mean_test_score'])\n",
    "    mediaTempo      = np.mean(modelo.cv_results_['mean_score_time'])\n",
    "    desvPadTempo    = np.std(modelo.cv_results_['mean_score_time'])\n",
    "    \n",
    "    objFile = open(caminhoArquivo, \"a\")\n",
    "    \n",
    "    linha = str(modelo.best_estimator_) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Acurácia Média: ' + str(mediaAcuracia) + ' +- ' + str(desvPadAcuracia) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Time: ' + str(mediaTempo) + ' +- ' + str(desvPadTempo) + \"\\n\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)   \n",
    "    \n",
    "    objFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abrindo os CSVs de treino e teste e separando os dados em x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dataframe treino: 59880\n",
      "Tamanho dataframe teste: 1354\n",
      "Total de dados: 61234\n"
     ]
    }
   ],
   "source": [
    "caminhoCSVTreino = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train_augmentation/treino_augmentation_normalizado_semPCA.csv\"\n",
    "caminhoCSVTeste  = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/teste_normalizado_semPCA.csv\"\n",
    "\n",
    "dataframeTreino  = pd.read_csv(caminhoCSVTreino)\n",
    "dataframeTeste   = pd.read_csv(caminhoCSVTeste)\n",
    "\n",
    "print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Só rodar a célula abaixo se quiser diminuir o tamanho do dataset para testes rápidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentual = 0.15\n",
    "\n",
    "# dataframeTreino = dataframeTreino[0:int(percentual * len(dataframeTreino))]\n",
    "# dataframeTeste  = dataframeTeste[0:int(percentual * len(dataframeTeste))]\n",
    "\n",
    "# print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "# print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "# print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando o Group K Fold para garantir que todos os frames de um mesmo áudio fiquem na mesma pasta em um K Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a validação cruzada, não posso deixar que um mesmo áudio seja usado tanto no treinamento quanto no teste. É preciso garantir que todos os frames de um determinado áudio façam parte ou do treinamento ou do teste.\n",
    "\n",
    "Fazendo \"groups\" ser igual ao nomes dos arquivos, é possível usar a classe GroupKFold para fazer o K Fold sem que os áudios se misturem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = np.array(dataframeTreino.iloc[:,1:-1].values.tolist() + dataframeTeste.iloc[:,1:-1].values.tolist())\n",
    "target = np.array(dataframeTreino.iloc[:,-1].values.tolist() + dataframeTeste.iloc[:,-1].values.tolist())\n",
    "groups = np.array(dataframeTreino.iloc[:,0].values.tolist() + dataframeTeste.iloc[:,0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTANDO COMO USAR ESSA CLASSE\n",
    "# objGroupKFold = GroupKFold(n_splits=3)\n",
    "\n",
    "# for trainIndex, testIndex in objGroupKFold.split(data, target, groups):\n",
    "#     xTrain, xTest = data[trainIndex], data[testIndex]\n",
    "#     yTrain, yTest = target[trainIndex], target[testIndex]\n",
    "    \n",
    "#     objKNN = KNeighborsClassifier()\n",
    "#     objKNN.fit(xTrain, yTrain)\n",
    "#     yPred = objKNN.predict(xTest)\n",
    "    \n",
    "#     print(\"Acurácia:\", accuracy_score(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_knn = [\n",
    "    {\n",
    "        'n_neighbors': [3,5,7,11,13],\n",
    "     \n",
    "        'weights': ['uniform', \n",
    "                    'distance'],\n",
    "     \n",
    "        'metric': ['euclidean', \n",
    "                   'manhattan', \n",
    "                   'chebyshev', \n",
    "                   'minkowski']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params_knn,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 86.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 121.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 146.5min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 181.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 204.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 228.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 252.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 296.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 335.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b26d4c00>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'chebyshev',\n",
       "                                     'minkowski'],\n",
       "                          'n_neighbors': [3, 5, 7, 11, 13],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "\n",
      "Acurácia Média: 0.8491197700623836 +- 0.0482713755700093\n",
      "\n",
      "Time: 664.0284180402756 +- 149.70311735613862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_knn, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_sgd = [\n",
    "    {\n",
    "        'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001],\n",
    "        'tol': [0.01, 0.001, 0.0001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_sgd = GridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    grid_params_sgd,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 53.0min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 56.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 72.4min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 101.3min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 106.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222480>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     r...0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 0.0001, 0.001],\n",
       "                          'loss': ['hinge', 'log', 'modified_huber',\n",
       "                                   'squared_hinge', 'perceptron'],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "              warm_start=False)\n",
      "\n",
      "Acurácia Média: 0.7823431426985008 +- 0.03336989435323899\n",
      "\n",
      "Time: 0.0383923124383997 +- 0.007287723825608822\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_sgd, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_tree = [\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [2,6,10,16],\n",
    "        'min_samples_leaf': [1,2,3,4,5],\n",
    "        'min_impurity_split': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid_params_tree,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 56.1min finished\n",
      "/home/dimi/venvIC/lib/python3.7/site-packages/sklearn/tree/tree.py:297: DeprecationWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222930>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_impurity_split': [1e-09, 1e-08, 1e-07, 1e-06],\n",
       "                          'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                          'min_samples_split': [2, 6, 10, 16]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tree.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=1e-08,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n",
      "Acurácia Média: 0.8042590717575203 +- 0.003410395435843564\n",
      "\n",
      "Time: 0.02983313649892807 +- 0.006236430319515586\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_tree, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_svm = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'degree': [3,4,5],\n",
    "        'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    SVC(),\n",
    "    grid_params_svm,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 73.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 102.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 138.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 173.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 220.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 251.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 301.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 342.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 394.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 457.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 537.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 608.6min\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed: 628.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2538318>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1],\n",
       "                          'decision_function_shape': ['ovo', 'ovr'],\n",
       "                          'degree': [3, 4, 5],\n",
       "                          'kernel': ['linear', 'poly', 'rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Acurácia Média: 0.8597021262697194 +- 0.12505282248445984\n",
      "\n",
      "Time: 200.83355978830357 +- 64.98283691136588\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_svm, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_perceptron = [\n",
    "    {\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'tol': [0.01, 0.001, 0.0001, 0.00001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_perceptron = GridSearchCV(\n",
    "    Perceptron(),\n",
    "    grid_params_perceptron,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2538660>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
       "                                  early_stopping=False, eta0=1.0,\n",
       "                                  fit_intercept=True, max_iter=1000,\n",
       "                                  n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "                                  random_state=0, shuffle=True, tol=0.001,\n",
       "                                  validation_fraction=0.1, verbose=0,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 1e-05, 0.0001, 0.001, 0.01],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_perceptron.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty='l1', random_state=0, shuffle=True, tol=0.01,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "Acurácia Média: 0.7224091191168305 +- 0.04986855845859998\n",
      "\n",
      "Time: 0.053537952899932864 +- 0.01618069056734965\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_perceptron, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_lda = [\n",
    "    {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'store_covariance': [True, False],\n",
    "        'tol': [1e-5,1e-4,1e-3]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_lda = GridSearchCV(\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    grid_params_lda,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222660>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                  priors=None, shrinkage=None,\n",
       "                                                  solver='svd',\n",
       "                                                  store_covariance=False,\n",
       "                                                  tol=0.0001),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'solver': ['svd', 'lsqr', 'eigen'],\n",
       "                          'store_covariance': [True, False],\n",
       "                          'tol': [1e-05, 0.0001, 0.001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lda.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=True, tol=1e-05)\n",
      "\n",
      "Acurácia Média: 0.7431655616160956 +- 0.0\n",
      "\n",
      "Time: 0.07487501479961253 +- 0.028658504177869436\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_lda, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos classificadores depois do gridsearch com data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatórios de classificação para os seguintes experimentos:\n",
    "\n",
    "1 - Treinamento com treino original e teste com teste aumentado\n",
    "\n",
    "2 - Treinamento com treino aumentado e teste com teste aumentado\n",
    "\n",
    "Nos dois casos os classificadores deverão ser instanciados com os melhores hiper-parâmetros encontrados nos gridsearchs realizados com e sem data augmentation. Ou seja, os hiper-parâmetros vão ser diferentes nos dois casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREINO ORIGINAL E TESTE AUMENTADO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Acurácia Média</th>\n",
       "      <th>Desvio Acc</th>\n",
       "      <th>Tempo Médio (ms)</th>\n",
       "      <th>Desvio Tempo (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>20.286400</td>\n",
       "      <td>5.594173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.572571</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>2.560655</td>\n",
       "      <td>0.147142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.657524</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>8.639207</td>\n",
       "      <td>2.007618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>0.017368</td>\n",
       "      <td>2.552352</td>\n",
       "      <td>0.135199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.576762</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>2.564775</td>\n",
       "      <td>0.146804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.543810</td>\n",
       "      <td>0.066438</td>\n",
       "      <td>2.491549</td>\n",
       "      <td>0.156450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>4.972882</td>\n",
       "      <td>0.472777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classificador  Acurácia Média  Desvio Acc  Tempo Médio (ms)  \\\n",
       "0           KNN        0.618286    0.010492         20.286400   \n",
       "1           SGD        0.572571    0.010899          2.560655   \n",
       "2           SVM        0.657524    0.011950          8.639207   \n",
       "3    Perceptron        0.630286    0.017368          2.552352   \n",
       "4           LDA        0.576762    0.011828          2.564775   \n",
       "5          Tree        0.543810    0.066438          2.491549   \n",
       "6           QDA        0.621333    0.009686          4.972882   \n",
       "\n",
       "   Desvio Tempo (ms)  \n",
       "0           5.594173  \n",
       "1           0.147142  \n",
       "2           2.007618  \n",
       "3           0.135199  \n",
       "4           0.146804  \n",
       "5           0.156450  \n",
       "6           0.472777  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = \"/home/dimi/Programming/IC2019/ML/relatorios_classificacao/SESA_Normalizado/tabelasGridSearch/treinoOriginal_testeAumentado/\"\n",
    "\n",
    "acuraciasKNN            = []\n",
    "mediasTempoKNN          = []\n",
    "desvPadsTempoKNN        = []\n",
    "acuraciasSGD            = []\n",
    "mediasTempoSGD          = []\n",
    "desvPadsTempoSGD        = []\n",
    "acuraciasSGD            = []\n",
    "mediasTempoSGD          = []\n",
    "desvPadsTempoSGD        = []\n",
    "acuraciasSVM            = []\n",
    "mediasTempoSVM          = []\n",
    "desvPadsTempoSVM        = []\n",
    "acuraciasPerceptron     = []\n",
    "mediasTempoPerceptron   = []\n",
    "desvPadsTempoPerceptron = []\n",
    "acuraciasLDA            = []\n",
    "mediasTempoLDA          = []\n",
    "desvPadsTempoLDA        = []\n",
    "acuraciasTree           = []\n",
    "mediasTempoTree         = []\n",
    "desvPadsTempoTree       = []\n",
    "acuraciasQDA            = []\n",
    "mediasTempoQDA          = []\n",
    "desvPadsTempoQDA        = []\n",
    "\n",
    "for jsonAtual in os.listdir(caminho):\n",
    "    \n",
    "    # SE NAO FOR UM JSON PULA A ITERACAO\n",
    "    if jsonAtual[-4:] != 'json':\n",
    "        continue\n",
    "    \n",
    "    with open(caminho+jsonAtual, 'r') as arquivo:\n",
    "        data = json.load(arquivo)\n",
    "        \n",
    "        if data[\"classificador\"] == \"KNeighborsClassifier\":\n",
    "            acuraciasKNN.append(data[\"accuracy\"])\n",
    "            mediasTempoKNN.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoKNN.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"SGDClassifier\":\n",
    "            acuraciasSGD.append(data[\"accuracy\"])\n",
    "            mediasTempoSGD.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoSGD.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"SVC\":\n",
    "            acuraciasSVM.append(data[\"accuracy\"])\n",
    "            mediasTempoSVM.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoSVM.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"Perceptron\":\n",
    "            acuraciasPerceptron.append(data[\"accuracy\"])\n",
    "            mediasTempoPerceptron.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoPerceptron.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"LinearDiscriminantAnalysis\":\n",
    "            acuraciasLDA.append(data[\"accuracy\"])\n",
    "            mediasTempoLDA.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoLDA.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"DecisionTreeClassifier\":\n",
    "            acuraciasTree.append(data[\"accuracy\"])\n",
    "            mediasTempoTree.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoTree.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        else:\n",
    "            acuraciasQDA.append(data[\"accuracy\"])\n",
    "            mediasTempoQDA.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoQDA.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "data = []\n",
    "\n",
    "linha = [\"KNN\"] #classificador\n",
    "linha.append(np.mean(acuraciasKNN))\n",
    "linha.append(np.std(acuraciasKNN)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoKNN))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoKNN)/len(mediasTempoKNN))**2)+(np.std(mediasTempoKNN))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"SGD\"] #classificador\n",
    "linha.append(np.mean(acuraciasSGD))\n",
    "linha.append(np.std(acuraciasSGD)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoSGD))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoSGD)/len(mediasTempoSGD))**2)+(np.std(mediasTempoSGD))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"SVM\"] #classificador\n",
    "linha.append(np.mean(acuraciasSVM))\n",
    "linha.append(np.std(acuraciasSVM)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoSVM))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoSVM)/len(mediasTempoSVM))**2)+(np.std(mediasTempoSVM))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"Perceptron\"] #classificador\n",
    "linha.append(np.mean(acuraciasPerceptron))\n",
    "linha.append(np.std(acuraciasPerceptron)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoPerceptron))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoPerceptron)/len(mediasTempoPerceptron))**2)+(np.std(mediasTempoPerceptron))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"LDA\"] #classificador\n",
    "linha.append(np.mean(acuraciasLDA))\n",
    "linha.append(np.std(acuraciasLDA)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoLDA))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoLDA)/len(mediasTempoLDA))**2)+(np.std(mediasTempoLDA))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"Tree\"] #classificador\n",
    "linha.append(np.mean(acuraciasTree))\n",
    "linha.append(np.std(acuraciasTree)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoTree))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoTree)/len(mediasTempoTree))**2)+(np.std(mediasTempoTree))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"QDA\"] #classificador\n",
    "linha.append(np.mean(acuraciasQDA))\n",
    "linha.append(np.std(acuraciasQDA)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoQDA))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoQDA)/len(mediasTempoQDA))**2)+(np.std(mediasTempoQDA))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "dataframe = pd.DataFrame(data=data, columns=[\"Classificador\", \"Acurácia Média\", \"Desvio Acc\", \"Tempo Médio (ms)\", \"Desvio Tempo (ms)\"])\n",
    "dataframe.to_csv(caminho+\"resultadosGridsearch_treinoOriginal_testeAumentado.csv\", index=False)\n",
    "\n",
    "print(\"TREINO ORIGINAL E TESTE AUMENTADO\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREINO AUMENTADO E TESTE AUMENTADO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>Acurácia Média</th>\n",
       "      <th>Desvio Acc</th>\n",
       "      <th>Tempo Médio (ms)</th>\n",
       "      <th>Desvio Tempo (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.812571</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>239.682469</td>\n",
       "      <td>81.869793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>2.472010</td>\n",
       "      <td>0.130714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>57.179256</td>\n",
       "      <td>18.615244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.726095</td>\n",
       "      <td>0.027389</td>\n",
       "      <td>2.474219</td>\n",
       "      <td>0.132640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.728952</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>2.480378</td>\n",
       "      <td>0.132170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.665333</td>\n",
       "      <td>0.130805</td>\n",
       "      <td>2.444092</td>\n",
       "      <td>0.121374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.652476</td>\n",
       "      <td>0.031962</td>\n",
       "      <td>4.848536</td>\n",
       "      <td>0.333545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classificador  Acurácia Média  Desvio Acc  Tempo Médio (ms)  \\\n",
       "0           KNN        0.812571    0.003733        239.682469   \n",
       "1           SGD        0.784000    0.007387          2.472010   \n",
       "2           SVM        0.810667    0.006213         57.179256   \n",
       "3    Perceptron        0.726095    0.027389          2.474219   \n",
       "4           LDA        0.728952    0.006335          2.480378   \n",
       "5          Tree        0.665333    0.130805          2.444092   \n",
       "6           QDA        0.652476    0.031962          4.848536   \n",
       "\n",
       "   Desvio Tempo (ms)  \n",
       "0          81.869793  \n",
       "1           0.130714  \n",
       "2          18.615244  \n",
       "3           0.132640  \n",
       "4           0.132170  \n",
       "5           0.121374  \n",
       "6           0.333545  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caminho = \"/home/dimi/Programming/IC2019/ML/relatorios_classificacao/SESA_Normalizado/tabelasGridSearch/treinoAumentado_testeAumentado/\"\n",
    "\n",
    "acuraciasKNN            = []\n",
    "mediasTempoKNN          = []\n",
    "desvPadsTempoKNN        = []\n",
    "acuraciasSGD            = []\n",
    "mediasTempoSGD          = []\n",
    "desvPadsTempoSGD        = []\n",
    "acuraciasSGD            = []\n",
    "mediasTempoSGD          = []\n",
    "desvPadsTempoSGD        = []\n",
    "acuraciasSVM            = []\n",
    "mediasTempoSVM          = []\n",
    "desvPadsTempoSVM        = []\n",
    "acuraciasPerceptron     = []\n",
    "mediasTempoPerceptron   = []\n",
    "desvPadsTempoPerceptron = []\n",
    "acuraciasLDA            = []\n",
    "mediasTempoLDA          = []\n",
    "desvPadsTempoLDA        = []\n",
    "\n",
    "for jsonAtual in os.listdir(caminho):\n",
    "    \n",
    "    # SE NAO FOR UM JSON PULA A ITERACAO\n",
    "    if jsonAtual[-4:] != 'json':\n",
    "        continue\n",
    "    \n",
    "    with open(caminho+jsonAtual, 'r') as arquivo:\n",
    "        data = json.load(arquivo)\n",
    "        \n",
    "        if data[\"classificador\"] == \"KNeighborsClassifier\":\n",
    "            acuraciasKNN.append(data[\"accuracy\"])\n",
    "            mediasTempoKNN.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoKNN.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"SGDClassifier\":\n",
    "            acuraciasSGD.append(data[\"accuracy\"])\n",
    "            mediasTempoSGD.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoSGD.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"SVC\":\n",
    "            acuraciasSVM.append(data[\"accuracy\"])\n",
    "            mediasTempoSVM.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoSVM.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"Perceptron\":\n",
    "            acuraciasPerceptron.append(data[\"accuracy\"])\n",
    "            mediasTempoPerceptron.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoPerceptron.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"LinearDiscriminantAnalysis\":\n",
    "            acuraciasLDA.append(data[\"accuracy\"])\n",
    "            mediasTempoLDA.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoLDA.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        elif data[\"classificador\"] == \"DecisionTreeClassifier\":\n",
    "            acuraciasTree.append(data[\"accuracy\"])\n",
    "            mediasTempoTree.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoTree.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "            \n",
    "        else:\n",
    "            acuraciasQDA.append(data[\"accuracy\"])\n",
    "            mediasTempoQDA.append(data[\"mediaTempoClassificacaoCadaAudio\"])\n",
    "            desvPadsTempoQDA.append(data[\"desvioTempoClassificacaoCadaAudio\"])\n",
    "\n",
    "            \n",
    "data = []\n",
    "\n",
    "linha = [\"KNN\"] #classificador\n",
    "linha.append(np.mean(acuraciasKNN))\n",
    "linha.append(np.std(acuraciasKNN)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoKNN))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoKNN)/len(mediasTempoKNN))**2)+(np.std(mediasTempoKNN))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"SGD\"] #classificador\n",
    "linha.append(np.mean(acuraciasSGD))\n",
    "linha.append(np.std(acuraciasSGD)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoSGD))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoSGD)/len(mediasTempoSGD))**2)+(np.std(mediasTempoSGD))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"SVM\"] #classificador\n",
    "linha.append(np.mean(acuraciasSVM))\n",
    "linha.append(np.std(acuraciasSVM)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoSVM))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoSVM)/len(mediasTempoSVM))**2)+(np.std(mediasTempoSVM))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"Perceptron\"] #classificador\n",
    "linha.append(np.mean(acuraciasPerceptron))\n",
    "linha.append(np.std(acuraciasPerceptron)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoPerceptron))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoPerceptron)/len(mediasTempoPerceptron))**2)+(np.std(mediasTempoPerceptron))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"LDA\"] #classificador\n",
    "linha.append(np.mean(acuraciasLDA))\n",
    "linha.append(np.std(acuraciasLDA)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoLDA))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoLDA)/len(mediasTempoLDA))**2)+(np.std(mediasTempoLDA))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"Tree\"] #classificador\n",
    "linha.append(np.mean(acuraciasTree))\n",
    "linha.append(np.std(acuraciasTree)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoTree))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoTree)/len(mediasTempoTree))**2)+(np.std(mediasTempoTree))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "linha = [\"QDA\"] #classificador\n",
    "linha.append(np.mean(acuraciasQDA))\n",
    "linha.append(np.std(acuraciasQDA)) #acuracia e desvio\n",
    "linha.append(1000*np.mean(mediasTempoQDA))\n",
    "linha.append(1000*(np.sum((np.array(desvPadsTempoQDA)/len(mediasTempoQDA))**2)+(np.std(mediasTempoQDA))**2)**(1/2)) #tempo e desvio\n",
    "data.append(linha)\n",
    "\n",
    "dataframe = pd.DataFrame(data=data, columns=[\"Classificador\", \"Acurácia Média\", \"Desvio Acc\", \"Tempo Médio (ms)\", \"Desvio Tempo (ms)\"])\n",
    "dataframe.to_csv(caminho+\"resultadosGridsearch_treinoAumentado_testeAumentado.csv\", index=False)\n",
    "\n",
    "print(\"TREINO AUMENTADO E TESTE AUMENTADO\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
