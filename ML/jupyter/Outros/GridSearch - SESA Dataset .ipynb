{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para fazer o Grid Search com alguns classificadores para o SESA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abrindo os CSVs de treino e teste e separando os dados em x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dataframe treino: 5988\n",
      "Tamanho dataframe teste: 1354\n",
      "Total de dados: 7342\n"
     ]
    }
   ],
   "source": [
    "caminhoCSVTreino = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train/treino_normalizado_semPCA.csv\"\n",
    "caminhoCSVTeste  = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/teste_normalizado_semPCA.csv\"\n",
    "\n",
    "dataframeTreino  = pd.read_csv(caminhoCSVTreino)\n",
    "dataframeTeste   = pd.read_csv(caminhoCSVTeste)\n",
    "\n",
    "print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando o Group K Fold para garantir que todos os frames de um mesmo áudio fiquem na mesma pasta em um K Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a validação cruzada, não posso deixar que um mesmo áudio seja usado tanto no treinamento quanto no teste. É preciso garantir que todos os frames de um determinado áudio façam parte ou do treinamento ou do teste.\n",
    "\n",
    "Fazendo \"groups\" ser igual ao nomes dos arquivos, é possível usar a classe GroupKFold para fazer o K Fold sem que os áudios se misturem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = np.array(dataframeTreino.iloc[:,1:-1].values.tolist() + dataframeTeste.iloc[:,1:-1].values.tolist())\n",
    "target = np.array(dataframeTreino.iloc[:,-1].values.tolist() + dataframeTeste.iloc[:,-1].values.tolist())\n",
    "groups = np.array(dataframeTreino.iloc[:,0].values.tolist() + dataframeTeste.iloc[:,0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8402777777777778\n",
      "Acurácia: 0.8242746219861055\n",
      "Acurácia: 0.8929301185124643\n"
     ]
    }
   ],
   "source": [
    "# TESTANDO COMO USAR ESSA CLASSE\n",
    "objGroupKFold = GroupKFold(n_splits=3)\n",
    "\n",
    "for trainIndex, testIndex in objGroupKFold.split(data, target, groups):\n",
    "    xTrain, xTest = data[trainIndex], data[testIndex]\n",
    "    yTrain, yTest = target[trainIndex], target[testIndex]\n",
    "    \n",
    "    objKNN = KNeighborsClassifier()\n",
    "    objKNN.fit(xTrain, yTrain)\n",
    "    yPred = objKNN.predict(xTest)\n",
    "    \n",
    "    print(\"Acurácia:\", accuracy_score(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_knn = [\n",
    "    {\n",
    "        'n_neighbors': [3,5,7,11,13,17],\n",
    "     \n",
    "        'weights': ['uniform', \n",
    "                    'distance'],\n",
    "     \n",
    "        'metric': ['euclidean', \n",
    "                   'manhattan', \n",
    "                   'chebyshev', \n",
    "                   'minkowski']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params_knn,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46f350a98>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'chebyshev',\n",
       "                                     'minkowski'],\n",
       "                          'n_neighbors': [3, 5, 7, 11, 13, 17],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
      "                     weights='distance') \n",
      "\n",
      "0.8703350585671479\n"
     ]
    }
   ],
   "source": [
    "print(gs_knn.best_estimator_, \"\\n\")\n",
    "print(gs_knn.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_sgd = [\n",
    "    {\n",
    "        'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001],\n",
    "        'tol': [0.01, 0.001, 0.0001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_sgd = GridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    grid_params_sgd,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46f325a98>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     r...0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 0.0001, 0.001],\n",
       "                          'loss': ['hinge', 'log', 'modified_huber',\n",
       "                                   'squared_hinge', 'perceptron'],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "\n",
      "0.8387360392263689\n"
     ]
    }
   ],
   "source": [
    "print(gs_sgd.best_estimator_, \"\\n\")\n",
    "print(gs_sgd.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_bagging = [\n",
    "    {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_features': [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_bagging = GridSearchCV(\n",
    "    BaggingClassifier(),\n",
    "    grid_params_bagging,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  60 | elapsed:  4.2min remaining:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46e812228>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=None,\n",
       "                                         oob_score=False, random_state=None,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
       "                          'n_estimators': [50, 100, 150, 200]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bagging.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.4, max_samples=1.0, n_estimators=200,\n",
      "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False) \n",
      "\n",
      "0.8975755924816127\n"
     ]
    }
   ],
   "source": [
    "print(gs_bagging.best_estimator_, \"\\n\")\n",
    "print(gs_bagging.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_svm = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'penalty': ['l2'],\n",
    "        'multi_class': ['ovr', 'crammer_singer']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    LinearSVC(),\n",
    "    grid_params_svm,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:    1.1s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  18 | elapsed:    3.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  18 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  18 | elapsed:    4.4s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed:    6.0s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed:    7.2s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   27.0s finished\n",
      "/home/dimi/venvIC/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46e8127c8>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1],\n",
       "                          'multi_class': ['ovr', 'crammer_singer'],\n",
       "                          'penalty': ['l2']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) \n",
      "\n",
      "0.8481340234268592\n"
     ]
    }
   ],
   "source": [
    "print(gs_svm.best_estimator_, \"\\n\")\n",
    "print(gs_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_perceptron = [\n",
    "    {\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'tol': [0.01, 0.001, 0.0001, 0.00001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_perceptron = GridSearchCV(\n",
    "    Perceptron(),\n",
    "    grid_params_perceptron,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1470s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0072s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 187 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 206 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 225 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa46eb1dde0>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
       "                                  early_stopping=False, eta0=1.0,\n",
       "                                  fit_intercept=True, max_iter=1000,\n",
       "                                  n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "                                  random_state=0, shuffle=True, tol=0.001,\n",
       "                                  validation_fraction=0.1, verbose=0,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 1e-05, 0.0001, 0.001, 0.01],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_perceptron.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty='l2', random_state=0, shuffle=True, tol=0.01,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "\n",
      "0.8319259057477526\n"
     ]
    }
   ],
   "source": [
    "print(gs_perceptron.best_estimator_, \"\\n\")\n",
    "print(gs_perceptron.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
