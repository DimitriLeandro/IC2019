{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para fazer o Grid Search com alguns classificadores para o SESA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoArquivo = \"/home/dimi/Programming/IC2019/ML/jupyter/Outros/resultadosGridsearchSESAAugmentation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados(modelo, caminhoArquivo):\n",
    "    \n",
    "    mediaAcuracia   = modelo.best_score_\n",
    "    desvPadAcuracia = np.std(modelo.cv_results_['mean_test_score'])\n",
    "    mediaTempo      = np.mean(modelo.cv_results_['mean_score_time'])\n",
    "    desvPadTempo    = np.std(modelo.cv_results_['mean_score_time'])\n",
    "    \n",
    "    objFile = open(caminhoArquivo, \"a\")\n",
    "    \n",
    "    linha = str(modelo.best_estimator_) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Acurácia Média: ' + str(mediaAcuracia) + ' +- ' + str(desvPadAcuracia) + \"\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)\n",
    "    \n",
    "    linha = 'Time: ' + str(mediaTempo) + ' +- ' + str(desvPadTempo) + \"\\n\\n\"\n",
    "    objFile.write(linha) \n",
    "    print(linha)   \n",
    "    \n",
    "    objFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abrindo os CSVs de treino e teste e separando os dados em x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dataframe treino: 59880\n",
      "Tamanho dataframe teste: 1354\n",
      "Total de dados: 61234\n"
     ]
    }
   ],
   "source": [
    "caminhoCSVTreino = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train_augmentation/treino_augmentation_normalizado_semPCA.csv\"\n",
    "caminhoCSVTeste  = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/teste_normalizado_semPCA.csv\"\n",
    "\n",
    "dataframeTreino  = pd.read_csv(caminhoCSVTreino)\n",
    "dataframeTeste   = pd.read_csv(caminhoCSVTeste)\n",
    "\n",
    "print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Só rodar a célula abaixo se quiser diminuir o tamanho do dataset para testes rápidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentual = 0.15\n",
    "\n",
    "# dataframeTreino = dataframeTreino[0:int(percentual * len(dataframeTreino))]\n",
    "# dataframeTeste  = dataframeTeste[0:int(percentual * len(dataframeTeste))]\n",
    "\n",
    "# print(\"Tamanho dataframe treino:\", len(dataframeTreino))\n",
    "# print(\"Tamanho dataframe teste:\", len(dataframeTeste))\n",
    "# print(\"Total de dados:\", len(dataframeTreino) + len(dataframeTeste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando o Group K Fold para garantir que todos os frames de um mesmo áudio fiquem na mesma pasta em um K Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a validação cruzada, não posso deixar que um mesmo áudio seja usado tanto no treinamento quanto no teste. É preciso garantir que todos os frames de um determinado áudio façam parte ou do treinamento ou do teste.\n",
    "\n",
    "Fazendo \"groups\" ser igual ao nomes dos arquivos, é possível usar a classe GroupKFold para fazer o K Fold sem que os áudios se misturem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = np.array(dataframeTreino.iloc[:,1:-1].values.tolist() + dataframeTeste.iloc[:,1:-1].values.tolist())\n",
    "target = np.array(dataframeTreino.iloc[:,-1].values.tolist() + dataframeTeste.iloc[:,-1].values.tolist())\n",
    "groups = np.array(dataframeTreino.iloc[:,0].values.tolist() + dataframeTeste.iloc[:,0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTANDO COMO USAR ESSA CLASSE\n",
    "# objGroupKFold = GroupKFold(n_splits=3)\n",
    "\n",
    "# for trainIndex, testIndex in objGroupKFold.split(data, target, groups):\n",
    "#     xTrain, xTest = data[trainIndex], data[testIndex]\n",
    "#     yTrain, yTest = target[trainIndex], target[testIndex]\n",
    "    \n",
    "#     objKNN = KNeighborsClassifier()\n",
    "#     objKNN.fit(xTrain, yTrain)\n",
    "#     yPred = objKNN.predict(xTest)\n",
    "    \n",
    "#     print(\"Acurácia:\", accuracy_score(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_knn = [\n",
    "    {\n",
    "        'n_neighbors': [3,5,7,11,13],\n",
    "     \n",
    "        'weights': ['uniform', \n",
    "                    'distance'],\n",
    "     \n",
    "        'metric': ['euclidean', \n",
    "                   'manhattan', \n",
    "                   'chebyshev', \n",
    "                   'minkowski']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params_knn,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 86.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 121.4min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 146.5min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 181.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 204.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 228.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 252.6min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 296.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 335.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b26d4c00>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'metric': ['euclidean', 'manhattan', 'chebyshev',\n",
       "                                     'minkowski'],\n",
       "                          'n_neighbors': [3, 5, 7, 11, 13],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='distance')\n",
      "\n",
      "Acurácia Média: 0.8491197700623836 +- 0.0482713755700093\n",
      "\n",
      "Time: 664.0284180402756 +- 149.70311735613862\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_knn, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_sgd = [\n",
    "    {\n",
    "        'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001],\n",
    "        'tol': [0.01, 0.001, 0.0001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_sgd = GridSearchCV(\n",
    "    SGDClassifier(),\n",
    "    grid_params_sgd,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 48.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 53.0min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 56.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 72.4min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 101.3min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 106.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222480>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     r...0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 0.0001, 0.001],\n",
       "                          'loss': ['hinge', 'log', 'modified_huber',\n",
       "                                   'squared_hinge', 'perceptron'],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "              shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "              warm_start=False)\n",
      "\n",
      "Acurácia Média: 0.7823431426985008 +- 0.03336989435323899\n",
      "\n",
      "Time: 0.0383923124383997 +- 0.007287723825608822\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_sgd, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_tree = [\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [2,6,10,16],\n",
    "        'min_samples_leaf': [1,2,3,4,5],\n",
    "        'min_impurity_split': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid_params_tree,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 55.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 56.1min finished\n",
      "/home/dimi/venvIC/lib/python3.7/site-packages/sklearn/tree/tree.py:297: DeprecationWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222930>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_impurity_split': [1e-09, 1e-08, 1e-07, 1e-06],\n",
       "                          'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                          'min_samples_split': [2, 6, 10, 16]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_tree.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=1e-08,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n",
      "Acurácia Média: 0.8042590717575203 +- 0.003410395435843564\n",
      "\n",
      "Time: 0.02983313649892807 +- 0.006236430319515586\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_tree, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_svm = [\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'degree': [3,4,5],\n",
    "        'decision_function_shape': ['ovo', 'ovr']\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    SVC(),\n",
    "    grid_params_svm,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 73.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 102.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 138.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 173.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 220.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 251.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 301.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 342.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 394.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 457.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 537.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 608.6min\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed: 628.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2538318>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1],\n",
       "                          'decision_function_shape': ['ovo', 'ovr'],\n",
       "                          'degree': [3, 4, 5],\n",
       "                          'kernel': ['linear', 'poly', 'rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovo', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Acurácia Média: 0.8597021262697194 +- 0.12505282248445984\n",
      "\n",
      "Time: 200.83355978830357 +- 64.98283691136588\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_svm, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_perceptron = [\n",
    "    {\n",
    "        'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha': [0.00001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "        'tol': [0.01, 0.001, 0.0001, 0.00001]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_perceptron = GridSearchCV(\n",
    "    Perceptron(),\n",
    "    grid_params_perceptron,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2538660>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
       "                                  early_stopping=False, eta0=1.0,\n",
       "                                  fit_intercept=True, max_iter=1000,\n",
       "                                  n_iter_no_change=5, n_jobs=None, penalty=None,\n",
       "                                  random_state=0, shuffle=True, tol=0.001,\n",
       "                                  validation_fraction=0.1, verbose=0,\n",
       "                                  warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'alpha': [1e-05, 1e-05, 0.0001, 0.001, 0.01],\n",
       "                          'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
       "                          'tol': [0.01, 0.001, 0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_perceptron.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty='l1', random_state=0, shuffle=True, tol=0.01,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "Acurácia Média: 0.7224091191168305 +- 0.04986855845859998\n",
      "\n",
      "Time: 0.053537952899932864 +- 0.01618069056734965\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_perceptron, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_lda = [\n",
    "    {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'store_covariance': [True, False],\n",
    "        'tol': [1e-5,1e-4,1e-3]\n",
    "    }\n",
    "]\n",
    "\n",
    "gs_lda = GridSearchCV(\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    grid_params_lda,\n",
    "    verbose=10,\n",
    "    cv=GroupKFold(n_splits=3).split(data, target, groups),\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x7fa2b2222660>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                  priors=None, shrinkage=None,\n",
       "                                                  solver='svd',\n",
       "                                                  store_covariance=False,\n",
       "                                                  tol=0.0001),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'solver': ['svd', 'lsqr', 'eigen'],\n",
       "                          'store_covariance': [True, False],\n",
       "                          'tol': [1e-05, 0.0001, 0.001]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lda.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=True, tol=1e-05)\n",
      "\n",
      "Acurácia Média: 0.7431655616160956 +- 0.0\n",
      "\n",
      "Time: 0.07487501479961253 +- 0.028658504177869436\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultados(gs_lda, caminhoArquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
