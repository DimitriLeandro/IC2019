{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de uma classe capaz de abrir os CSVs de treino e teste do SESA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe deverá ser capaz de receber o caminho de um CSV com dados de TREINO, treinar os classificadores e classificar os dados de outros CSVs de TESTE.\n",
    "\n",
    "A ideia é criar uma função para receber um único CSV de treino para treinar os classificadores, e eles deverão ficar armazenados na classe, afinal, se a cada CSV de teste eu for fazer o treino antes, o processamento vai ficar pesado. Muito melhor fazer o treinamento uma única vez e depois usar os objetos das classes dos classificadores para testar outros CSVs.\n",
    "\n",
    "Os melhores classificadores de acordo com o trabalho enviado ao Workshop NUVEM da UFABC, usando esse mesmo dataset, foram:\n",
    "\n",
    "**1) SGD:** Obteve a segunda melhor acurácia e o melhor tempo de processamento.\n",
    "\n",
    "**2) Bagging:** Apesar de ter ganhado de apenas 3 classificadores no quesito tempo de processamento, obteve a melhor acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abrindo os CSVs de treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar tudo, vou usar CSVs com dados ficitícios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import mode \n",
    "from random import randint\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONTANDO O CAMINHO PROS CSVS\n",
    "csvTreino = '/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train/treino_normalizado_semPCA.csv'\n",
    "csvTeste  = '/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/teste_normalizado_semPCA.csv'\n",
    "\n",
    "# ABRINDO OS CSVS\n",
    "dataframeTreino = pd.read_csv(csvTreino) \n",
    "dataframeTeste  = pd.read_csv(csvTeste) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para fazer o TREINAMENTO dos classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, vou escrever as funções responsáveis por treinar os classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para separar o dataframe em X e Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preciso de uma função que pegue o dataframe devolva dois arrays: xTrain e yTrain. Ai depois é só usar esses arrays para treinar os classificadores.\n",
    "\n",
    "ESSA FUNÇÃO TAMBÉM SERÁ USADA NA PARTE DO TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separarDataframeXeY(dataframe):\n",
    "    # PRIMEIRO, MONTO O X (POSSO EXCLUIR A PRIMEIRA COLUNA \"ARQUIVOS\" E A ÚLTIMA \"CLASSE\")\n",
    "    x = dataframe[dataframe.columns[1:-1]]\n",
    "    \n",
    "    # AGORA, MONTO O Y\n",
    "    y = dataframe[dataframe.columns[-1]]\n",
    "    \n",
    "    # CONVERTO TUDO PRA TUPLA NORMAL \n",
    "    x = x.values.tolist()\n",
    "    y = y.values.tolist()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTrain, yTrain = separarDataframeXeY(dataframeTreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para instanciar classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como eu não sei se vou usar mais classificadores depois, então vou criar um array de classificadores, assim na hora de treinar eu faço um for loop e vou treinando tudo o que tiver dentro.\n",
    "\n",
    "Essa função recebe apenas o nome das classes a serem instanciadas. Por exemplo, envie [\"SGDClassifier(params)\", \"BaggingClassifier(params)\"] para receber um array de objetos dessas classes.\n",
    "\n",
    "Além disso, para fazer a validação cruzada, vou instânciar **kCrossValidation** vezes o mesmo classificador. Cada um vai ser treinado com dados diferentes, logo, o resultado será diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciarClassificadores(arrayStringsClassesClassificadores, kCrossValidation=10, verbose=False):\n",
    "    \n",
    "    arrayObjClassificadores = []\n",
    "    \n",
    "    for classe in arrayStringsClassesClassificadores:\n",
    "        for k in range(kCrossValidation):\n",
    "            \n",
    "            if verbose == True:\n",
    "                print(\"Instanciando o \" + str(k+1) + \"º objeto da classe\", classe)\n",
    "            \n",
    "            arrayObjClassificadores.append(eval(classe))\n",
    "        \n",
    "    return arrayObjClassificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciando o 1º objeto da classe SGDClassifier()\n",
      "Instanciando o 2º objeto da classe SGDClassifier()\n",
      "Instanciando o 3º objeto da classe SGDClassifier()\n",
      "Instanciando o 1º objeto da classe BaggingClassifier()\n",
      "Instanciando o 2º objeto da classe BaggingClassifier()\n",
      "Instanciando o 3º objeto da classe BaggingClassifier()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                   n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                   warm_start=False),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                   n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                   warm_start=False),\n",
       " BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                   max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                   n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                   warm_start=False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayObjClassificadores = instanciarClassificadores([\"SGDClassifier()\", \"BaggingClassifier()\"], 3, True)\n",
    "arrayObjClassificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para criar um array apenas com os nomes dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou precisar de um array que contenha o nome de cada arquivo de um CSV, sem repetições. Isso será necessário para criar um dataframe contendo apenas linhas que digam respeito às janelas de um único áudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterNomesArquivos(dataframe):\n",
    "    return dataframe[dataframe.columns[0]].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explosion_208.wav', 'explosion_057.wav', 'casual_054.wav', 'explosion_195.wav', 'gunshot_091.wav']\n"
     ]
    }
   ],
   "source": [
    "print(obterNomesArquivos(dataframeTeste)[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para segmentar o dataframe de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada classificador será treinado só com **x%** de dados do dataframe de treino. Assim, será possível fazer o bootstrap na validação cruzada. Essa função vai receber um dataframe, remover as linhas referentes à alguns arquivos e devolver o novo dataframe segmentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentarDataframeTreino(dataframeTreino, percentual=0.75):\n",
    "    \n",
    "    # PEGO O NOME DOS AUDIOS NO DATAFRAME\n",
    "    nomesAudios = obterNomesArquivos(dataframeTreino)\n",
    "    \n",
    "    # VEJO QUANTOS ARQUIVOS EU VOU TER QUE TIRAR DO DATAFRAME\n",
    "    qtdArquivosParaRemover = int(round((1 - percentual) * len(nomesAudios)))\n",
    "    \n",
    "    # SELECIONANDO OS ARQUIVOS QUE EU VOU REMOVER\n",
    "    arquivosParaRemover = []\n",
    "    for i in range(qtdArquivosParaRemover):\n",
    "        indexSorteado = randint(0, len(nomesAudios) - 1)\n",
    "        arquivosParaRemover.append(nomesAudios[indexSorteado])\n",
    "        del nomesAudios[indexSorteado]\n",
    "        \n",
    "    # REMOVENDO \n",
    "    for arquivoAtualRemover in arquivosParaRemover:\n",
    "        dataframeTreino = dataframeTreino[dataframeTreino[\"nomeArquivo\"] != arquivoAtualRemover]\n",
    "    \n",
    "    # RETORNANDO\n",
    "    return dataframeTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframeSegmentado = segmentarDataframeTreino(dataframeTreino, percentual=0.01)\n",
    "#dataframeSegmentado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para treinar os classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer a validação cruzada, essa função vai receber um dataframe de treino e, para cada classificador, ela deverá excluir um percentual de arquivos do dataframe e só depois treinar o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarClassificadores(dataframeTreino, arrayObjClassificadores, percentual=0.75, verbose=False):\n",
    "    \n",
    "    # PARA CADA CLASSIFICADOR\n",
    "    for i, objClassificador in enumerate(arrayObjClassificadores):\n",
    "        \n",
    "        # EU REMOVO ALGUNS ARQIVOS DO DATAFRAME ALEATORIAMENTE ATE O PERCENTUAL DEFINIDO\n",
    "        dataframeTreinoSegmentado = segmentarDataframeTreino(dataframeTreino, percentual)\n",
    "        \n",
    "        # SEPARO O NOVO DATAFRAME EM X E Y\n",
    "        xTrain, yTrain = separarDataframeXeY(dataframeTreinoSegmentado)\n",
    "        \n",
    "        # FAÇO UM FIT NO CLASSIFICADOR\n",
    "        tempoInicio = time.time()\n",
    "        arrayObjClassificadores[i].fit(xTrain, yTrain)\n",
    "        tempoFim = time.time()\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(\"Tempo de treinamento do\", objClassificador.__class__.__name__, \"(segundos):\", tempoFim-tempoInicio)\n",
    "        \n",
    "    return arrayObjClassificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de treinamento do SGDClassifier (segundos): 0.43140339851379395\n",
      "Tempo de treinamento do SGDClassifier (segundos): 0.46740198135375977\n",
      "Tempo de treinamento do SGDClassifier (segundos): 0.48363518714904785\n",
      "Tempo de treinamento do BaggingClassifier (segundos): 4.530040979385376\n",
      "Tempo de treinamento do BaggingClassifier (segundos): 4.631577253341675\n",
      "Tempo de treinamento do BaggingClassifier (segundos): 4.6139349937438965\n"
     ]
    }
   ],
   "source": [
    "arrayObjClassificadores = treinarClassificadores(dataframeTreino, arrayObjClassificadores, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para unir as três funções anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função vai unir as três funções que foram criadas. Ela vai receber o dataframe de treino e um array de strings contendo os classificadores desejados. \n",
    "\n",
    "Em primeiro lugar, ela vai usar a função **separarDataframeXeY** para gerar xTrain e yTrain. Depois, vai usar **instanciarClassificadores** para gerar um array com os classificadores desejados. Por fim, vai treiná-los usando **treinarClassificadores()**.\n",
    "\n",
    "Ela retorna o array de classificadores com todos eles já treinados e prontos para serem usados para predizer dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarETreinarClassificadores(dataframeTreino, arrayStringsClassesClassificadores, kCrossValidation=10, percentual=0.75, verbose=False):\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Começando o treinamento dos classificadores\")\n",
    "    \n",
    "    arrayObjClassificadores = instanciarClassificadores(arrayStringsClassesClassificadores, kCrossValidation, verbose)\n",
    "    arrayObjClassificadores = treinarClassificadores(dataframeTreino, arrayObjClassificadores, percentual, verbose)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"Classificadores treinados\")\n",
    "    \n",
    "    return arrayObjClassificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#arrayObjClassificadores = criarETreinarClassificadores(dataframeTreino, [\"KNeighborsClassifier()\", \"SGDClassifier()\", \"BaggingClassifier()\"], kCrossValidation=3, verbose=True)\n",
    "#arrayObjClassificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para fazer o TESTE e calcular métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos implementar as funções responsáveis por pegar um CSV, classificá-lo e calcular as métricas. A classificação deverá ser feita baseada na MODA das classificações de cada janela de um determinado áudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para calcular a moda das classificações de um único áudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada janela de um único áudio será classificada. Depois, para dar um veredito para o áudio como um todo, precisamos tirar a moda das classificações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularModa(yPredCadaJanela):\n",
    "    return mode(yPredCadaJanela)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA TESTAR VOU FAZER UM PREDICT USANDO O XTRAIN MESMO, SÓ PRA VER\n",
    "a = [\"casual\", \"gunshot\", \"gunshot\", \"explosion\", \"siren\"]\n",
    "print(calcularModa(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para para predizer um conjunto de dados xTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função receberá uma matriz contendo apenas features de um único áudio e um classificador. Ela vai classificar todas as janelas desse áudio e utilizar a função da moda para dar um veredito sobre esse único áudio. \n",
    "\n",
    "A matriz já vai ter que vir arrumada para essa função. As funções que lidam com o pandas para deixar tudo bonitinho vão vir depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predizerUnicoAudio(xTest, classificador):\n",
    "    \n",
    "    yPredCadaJanela = classificador.predict(xTest).tolist()\n",
    "    \n",
    "#     print(\"Janelas classificadas como casual:\", yPredCadaJanela.count(\"casual\"))\n",
    "#     print(\"Janelas classificadas como gunshot:\", yPredCadaJanela.count(\"gunshot\"))\n",
    "#     print(\"Janelas classificadas como explosion:\", yPredCadaJanela.count(\"explosion\"))\n",
    "#     print(\"Janelas classificadas como siren:\", yPredCadaJanela.count(\"siren\"))\n",
    "    \n",
    "    return calcularModa(yPredCadaJanela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predizerUnicoAudio(xTrain, arrayObjClassificadores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para criar um array apenas com os nomes dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou precisar de um array que contenha o nome de cada arquivo de um CSV de teste, sem repetições. Isso será necessário para criar um dataframe contendo apenas linhas que digam respeito às janelas de um único áudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterNomesArquivos(dataframe):\n",
    "    return dataframe[dataframe.columns[0]].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obterNomesArquivos(dataframeTeste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para criar um dataframe contendo apenas as linhas referentes a um único áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterDataframeUnicoAudio(dataframe, arquivo):\n",
    "    #print(\"Obtendo dataframe do áudio\", arquivo)\n",
    "    dataframeArquivoSelecionado = dataframe.loc[dataframe[dataframe.columns[0]] == arquivo]\n",
    "    #print(\"Primeiro valor do dataframe:\", dataframeArquivoSelecionado[dataframeArquivoSelecionado.columns[1]].values.tolist()[0])\n",
    "    return dataframeArquivoSelecionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframeAudioAtual = obterDataframeUnicoAudio(dataframeTeste, 'D_3.wav')\n",
    "# dataframeAudioAtual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para predizer um único áudio e retornar as classificações real e predita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pois bem, já temos a função de predizer um único áudio, mas ela precisa receber ua matriz bonitinha que só contenha features e que não seja do tipo pandas. \n",
    "\n",
    "A função proposta agora deve receber o dataframe tipo pandas de um único áudio, separar o que é xTest e o que é yReal, mandar classificar xTest e devolver yReal e yPred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterYRealYPredUnicoAudio(dataframeUnicoAudio, classificador):\n",
    "    # PRIMEIRO EU SEPARO O QUE E X E Y\n",
    "    xTest, arrayYReal = separarDataframeXeY(dataframeUnicoAudio)\n",
    "    \n",
    "    # FACO YREAL SER UM VALOR UNICO JA QUE A FUNCAO ACIMA RETORNA UM ARRAY Y\n",
    "    yReal = arrayYReal[0]\n",
    "    \n",
    "    # PREDIZENDO A CLASSE DO AUDIO EM QUESTAO (A FUNCAO ABAIXO JA RETORNA A MODA)\n",
    "    yPred = predizerUnicoAudio(xTest, classificador)\n",
    "    \n",
    "    #print(\"Classificacao real:\", yReal)\n",
    "    #print(\"Classificação atribuída:\", yPred)\n",
    "    \n",
    "    return yReal, yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yRealAudioAtual, yPredAudioAtual = obterYRealYPredUnicoAudio(dataframeAudioAtual, arrayObjClassificadores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para classificar um dataframe de teste inteiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo vai receber um dataframe e um classificador. Depois disso ela vai:\n",
    "\n",
    "1) Obter um array com o nome dos arquivos desse dataframe utilizando a função **obterNomesArquivos**;\n",
    "\n",
    "2) Para cada arquivo no dataframe, ela vai criar um novo dataframe contendo as janelas apenas desse único áudio, utilizando, para isso, a função **obterDataframeUnicoAudio**;\n",
    "\n",
    "3) Obter a classificação real e a predita para cada um dos arquivos utilizando a função **obterYRealYPredUnicoAudio**;\n",
    "\n",
    "4) Com tudo isso, ela vai montar os arrays yTest e yPred;\n",
    "\n",
    "5) Retornar o classification report do sklearn como um DICT (depois fica bem facil de transformar em JSON) com todas as informações de precisão, recall, acurácia e tal.\n",
    "\n",
    "A função que vai salvar o classification report, convertendo-o para um JSON será implementada a diante. Lembrando que essa função também vai ficar responsável por colocar o nome do classificador utilizado no classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificarDataframeCompleto(dataframeTeste, classificador, verbose=False):\n",
    "    \n",
    "    print(\"Classificando com o \", classificador.__class__.__name__)\n",
    "    \n",
    "    # CRIANDO OS ARRAYS GERAIS\n",
    "    yRealCadaAudio = []\n",
    "    yPredCadaAudio = []\n",
    "    \n",
    "    # PEGANDO O NOME DOS ARQUIVOS QUE ESTAO NO DATAFRAME\n",
    "    arrayNomesArquivos = obterNomesArquivos(dataframeTeste)\n",
    "    totalArquivos = len(arrayNomesArquivos)\n",
    "    \n",
    "    # PARA CADA ARQUIVO NO DATAFRAME DE TESTE\n",
    "    for i, arquivo in enumerate(arrayNomesArquivos):\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(\"Classificando \" + arquivo + \". Arquivo\", i+1, \"de\", totalArquivos, \"->\", str(100*((i+1)/totalArquivos))+\"%\")\n",
    "        \n",
    "        # EU CRIO UM DATAFRAME CONTENDO APENAS AS LINHAS DO AUDIO ATUAL\n",
    "        dataframeAudioAtual = obterDataframeUnicoAudio(dataframeTeste, arquivo)\n",
    "        \n",
    "        # E OBTENHO, PARA ESSE AUDIO, A CLASSIFICACAO REAL E A PREDITA\n",
    "        yRealAtual, yPredAtual = obterYRealYPredUnicoAudio(dataframeAudioAtual, classificador)\n",
    "        \n",
    "        # COLOCO O RESULTADO NOS ARRAYS GERAIS\n",
    "        yRealCadaAudio.append(yRealAtual)\n",
    "        yPredCadaAudio.append(yPredAtual)\n",
    "        \n",
    "    # CRIANDO O CLASSIFICATION REPORT. PARA FAZER ELE PARECER UM JSON, TEM QUE COLOCAR output_dict=True\n",
    "    # ASSIM ELE RETORNA UM DICT QUE DEPOIS VAI SER CONVERTIDO PRA JSON E SER SALVO EM ALGUM LUGAR\n",
    "    dictRelatorio = classification_report(yRealCadaAudio, yPredCadaAudio, digits=3, output_dict=True)\n",
    "    \n",
    "    # COLOCANDO O NOME DO CLASSIFICADOR NO DICIONARIO\n",
    "    dictRelatorio['classificador'] = classificador.__class__.__name__\n",
    "    \n",
    "    return dictRelatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para salvar o classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função vai receber um classification report como um DICT, converte-lo para JSON e salvar num diretório. Dentro desse dicionário já vai vir escrito qual foi o classificador utilizado, pois a função **classificarDataframeCompleto** coloca essa informação antes de retornar esse dicionário do relatório de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvarRelatorioClassificacao(dictRelatorio, diretorioOndeSalvar, nomeDatasetTreino):\n",
    "    \n",
    "    nomeJSON = \"relatorio_\" + nomeDatasetTreino + \"_\" + str(time.time()) + \".json\"\n",
    "    \n",
    "    print(\"Salvando as informações num JSON:\", nomeJSON)\n",
    "    \n",
    "    with open(diretorioOndeSalvar + nomeJSON, 'w') as json_file:\n",
    "        json.dump(dictRelatorio, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diretorio         = \"/home/dimi/Programming/IC2019/ML/datasets/SESA/\"\n",
    "#nomeDatasetTreino = \"testeEscalonado53D\"\n",
    "#salvarRelatorioClassificacao(dictRelatorio, diretorio, nomeDatasetTreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para classificar um dataset com todos os classificadores e gerar os relatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é a função principal da parte de treinamento de dataset, pois ela vai receber um dataset e o array de classificadores já treinados e, para cada classificador, ela vai garar um relátorio de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificarDataframe(dataframeTeste, arrayObjClassificadores, diretorioOndeSalvar, nomeDatasetTreino, verbose=False):\n",
    "    \n",
    "    print(\"Começando a classificar o dataset\", nomeDatasetTreino)\n",
    "    \n",
    "    # PARA CADA CLASSIFICADOR\n",
    "    for classificadorAtual in arrayObjClassificadores:\n",
    "        \n",
    "        # EU GERO O RELATORIO DE CLASSIFICACAO COMO UM DICIONARIO\n",
    "        dictRelatorioAtual = classificarDataframeCompleto(dataframeTeste, classificadorAtual, verbose)\n",
    "        \n",
    "        # E SALVO AS INFORMACOES COMO JSON\n",
    "        salvarRelatorioClassificacao(dictRelatorioAtual, diretorioOndeSalvar, nomeDatasetTreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalmente criando e testando a classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A classe deverá ser capaz de receber o caminho de um CSV com dados de TREINO, treinar os classificadores e classificar os dados de outros CSVs de TESTE.\n",
    "#A ideia é criar uma função para receber um único CSV de treino para treinar os classificadores, e eles deverão ficar armazenados na classe, afinal, se a cada CSV de teste eu for fazer o treino antes, o processamento vai ficar pesado. Muito melhor fazer o treinamento uma única vez e depois usar os objetos das classes dos classificadores para testar outros CSVs.\n",
    "\n",
    "# Toda a implementação da classe está muito bem descrita no jupyter \"Implementacao de classe para treinamento e classificacao de CSVs\"\n",
    "\n",
    "# Usando a classe\n",
    "# 1) Crie o caminho para o CSV de TREINAMENTO e abra-o como um pandas dataframe;\n",
    "# 2) Utilizando o dataframe de treinamento aberto, crie e treine os classificadores desejados;\n",
    "# 3) Crie o caminho para o CSV de TESTE, setando as váriaveis diretorio e nomeDataset;\n",
    "# 4) Classifique o dataset de TESTE aberto, especificando onde o JSON do relátorio deve ser salvo\n",
    "# Os passos 3 e 4 podem ser repetidos caso se deseje classificar vários datasets de TESTE.\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import mode \n",
    "from random import randint\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "class TreinarEClassificar:\n",
    "\n",
    "\tdef separarDataframeXeY(self, dataframe):\n",
    "\t\t# Função para separar o dataframe em X e Y\n",
    "\t\t# Preciso de uma função que pegue o dataframe devolva dois arrays: xTrain e yTrain. Ai depois é só usar esses arrays para treinar os classificadores.\n",
    "\n",
    "\t\t# ESSA FUNÇÃO TAMBÉM SERÁ USADA NA PARTE DO TESTE\n",
    "\n",
    "\t\t# PRIMEIRO, MONTO O X (POSSO EXCLUIR A PRIMEIRA COLUNA \"ARQUIVOS\" E A ÚLTIMA \"CLASSE\")\n",
    "\t\tx = dataframe[dataframe.columns[1:-1]]\n",
    "\t\t\n",
    "\t\t# AGORA, MONTO O Y\n",
    "\t\ty = dataframe[dataframe.columns[-1]]\n",
    "\t\t\n",
    "\t\t# CONVERTO TUDO PRA TUPLA NORMAL \n",
    "\t\tx = x.values.tolist()\n",
    "\t\ty = y.values.tolist()\n",
    "\t\t\n",
    "\t\treturn x, y\n",
    "\n",
    "\tdef instanciarClassificadores(self, arrayStringsClassesClassificadores, kCrossValidation=10, verbose=False):\n",
    "\t\t# Função para instanciar classificadores\n",
    "\t\t# Como eu não sei se vou usar mais classificadores depois, então vou criar um array de classificadores, assim na hora de treinar eu faço um for loop e vou treinando tudo o que tiver dentro.\n",
    "\n",
    "\t\t# Essa função recebe apenas o nome das classes a serem instanciadas. Por exemplo, envie [\"SGDClassifier(params)\", \"BaggingClassifier(params)\"] para receber um array de objetos dessas classes.\n",
    "\t\t\n",
    "\t\t#Além disso, para fazer a validação cruzada, vou instânciar kCrossValidation vezes o mesmo classificador. Cada um vai ser treinado com dados diferentes, logo, o resultado será diferente.\n",
    "\n",
    "\t\tarrayObjClassificadores = []\n",
    "\t\t\n",
    "\t\tfor classe in arrayStringsClassesClassificadores:\n",
    "\t\t\tfor k in range(kCrossValidation):\n",
    "\t\t\t\t\n",
    "\t\t\t\tif verbose == True:\n",
    "\t\t\t\t\tprint(\"Instanciando o \" + str(k+1) + \"º objeto da classe\", classe)\n",
    "\t\t\t\t\n",
    "\t\t\t\tarrayObjClassificadores.append(eval(classe))\n",
    "\t\t\t\n",
    "\t\treturn arrayObjClassificadores\n",
    "\n",
    "\tdef obterNomesArquivos(self, dataframe):\n",
    "\t\t# Função para criar um array apenas com os nomes dos arquivos\n",
    "\t\t# Vou precisar de um array que contenha o nome de cada arquivo de um CSV de teste, sem repetições. Isso será necessário para criar um dataframe contendo apenas linhas que digam respeito às janelas de um único áudio.\n",
    "\t\treturn dataframe[dataframe.columns[0]].unique().tolist()\n",
    "\n",
    "\tdef segmentarDataframeTreino(self, dataframeTreino, percentual=0.75):\n",
    "\t\t#Função para segmentar o dataframe de treino\n",
    "\t\t#Cada classificador será treinado só com x% de dados do dataframe de treino. Assim, será possível fazer o bootstrap na validação cruzada. Essa função vai receber um dataframe, remover as linhas referentes à alguns arquivos e devolver o novo dataframe segmentado.\n",
    "\n",
    "\t\t# PEGO O NOME DOS AUDIOS NO DATAFRAME\n",
    "\t\tnomesAudios = self.obterNomesArquivos(dataframeTreino)\n",
    "\t\t\n",
    "\t\t# VEJO QUANTOS ARQUIVOS EU VOU TER QUE TIRAR DO DATAFRAME\n",
    "\t\tqtdArquivosParaRemover = int(round((1 - percentual) * len(nomesAudios)))\n",
    "\t\t\n",
    "\t\t# SELECIONANDO OS ARQUIVOS QUE EU VOU REMOVER\n",
    "\t\tarquivosParaRemover = []\n",
    "\t\tfor i in range(qtdArquivosParaRemover):\n",
    "\t\t\tindexSorteado = randint(0, len(nomesAudios) - 1)\n",
    "\t\t\tarquivosParaRemover.append(nomesAudios[indexSorteado])\n",
    "\t\t\tdel nomesAudios[indexSorteado]\n",
    "\t\t\t\n",
    "\t\t# REMOVENDO \n",
    "\t\tfor arquivoAtualRemover in arquivosParaRemover:\n",
    "\t\t\tdataframeTreino = dataframeTreino[dataframeTreino[\"nomeArquivo\"] != arquivoAtualRemover]\n",
    "\t\t\n",
    "\t\t# RETORNANDO\n",
    "\t\treturn dataframeTreino\n",
    "\n",
    "\tdef treinarClassificadores(self, dataframeTreino, arrayObjClassificadores, percentual=0.75, verbose=False):\n",
    "\t\t# Função para treinar os classificadores\n",
    "\t\t#Para fazer a validação cruzada, essa função vai receber um dataframe de treino e, para cada classificador, ela deverá excluir um percentual de arquivos do dataframe e só depois treinar o classificador.\n",
    "\t\t\n",
    "\t\t# PARA CADA CLASSIFICADOR\n",
    "\t\tfor i, objClassificador in enumerate(arrayObjClassificadores):\n",
    "\t\t\t\n",
    "\t\t\t# EU REMOVO ALGUNS ARQIVOS DO DATAFRAME ALEATORIAMENTE ATE O PERCENTUAL DEFINIDO\n",
    "\t\t\tdataframeTreinoSegmentado = self.segmentarDataframeTreino(dataframeTreino, percentual)\n",
    "\t\t\t\n",
    "\t\t\t# SEPARO O NOVO DATAFRAME EM X E Y\n",
    "\t\t\txTrain, yTrain = self.separarDataframeXeY(dataframeTreinoSegmentado)\n",
    "\t\t\t\n",
    "\t\t\t# FAÇO UM FIT NO CLASSIFICADOR\n",
    "\t\t\ttempoInicio = time.time()\n",
    "\t\t\tarrayObjClassificadores[i].fit(xTrain, yTrain)\n",
    "\t\t\ttempoFim = time.time()\n",
    "\t\t\t\n",
    "\t\t\tif verbose == True:\n",
    "\t\t\t\tprint(\"Tempo de treinamento do\", objClassificador.__class__.__name__, \"(segundos):\", tempoFim-tempoInicio)\n",
    "\t\t\t\n",
    "\t\treturn arrayObjClassificadores\n",
    "\n",
    "\tdef criarETreinarClassificadores(self, dataframeTreino, arrayStringsClassesClassificadores, kCrossValidation=10, percentual=0.75, verbose=False):\n",
    "\t\t# Função para unir as três funções anteriores\n",
    "\t\t# Essa função vai unir as três funções que foram criadas. Ela vai receber o dataframe de treino e um array de strings contendo os classificadores desejados.\n",
    "\t\t# Em primeiro lugar, ela vai usar a função separarDataframeXeY para gerar xTrain e yTrain. Depois, vai usar instanciarClassificadores para gerar um array com os classificadores desejados. Por fim, vai treiná-los usando treinarClassificadores().\n",
    "\t\t# Ela retorna o array de classificadores com todos eles já treinados e prontos para serem usados para predizer dados.\n",
    "\t\t\n",
    "\t\tif verbose == True:\n",
    "\t\t\tprint(\"Começando o treinamento dos classificadores\")\n",
    "\t\t\n",
    "\t\tarrayObjClassificadores = instanciarClassificadores(arrayStringsClassesClassificadores, kCrossValidation, verbose)\n",
    "\t\tarrayObjClassificadores = treinarClassificadores(dataframeTreino, arrayObjClassificadores, percentual, verbose)\n",
    "\t\t\n",
    "\t\tif verbose == True:\n",
    "\t\t\tprint(\"Classificadores treinados\")\n",
    "\t\t\n",
    "\t\treturn arrayObjClassificadores\n",
    "\n",
    "\tdef calcularModa(self, yPredCadaJanela):\n",
    "\t\t# Função para calcular a moda das classificações de um único áudio\n",
    "\t\t# Cada janela de um único áudio será classificada. Depois, para dar um veredito para o áudio como um todo, precisamos tirar a moda das classificações.\n",
    "\t\treturn mode(yPredCadaJanela)[0][0]\n",
    "\n",
    "\tdef predizerUnicoAudio(self, xTest, classificador):\n",
    "\t\t# Função para para predizer um conjunto de dados xTest\n",
    "\t\t# Essa função receberá uma matriz contendo apenas features de um único áudio e um classificador. Ela vai classificar todas as janelas desse áudio e utilizar a função da moda para dar um veredito sobre esse único áudio.\n",
    "\t\t# A matriz já vai ter que vir arrumada para essa função. As funções que lidam com o pandas para deixar tudo bonitinho vão vir depois.\n",
    "\t\tyPredCadaJanela = classificador.predict(xTest).tolist()\n",
    "\t\treturn self.calcularModa(yPredCadaJanela)\n",
    "\n",
    "\tdef obterDataframeUnicoAudio(self, dataframe, arquivo):\n",
    "\t\t# Função para criar um dataframe contendo apenas as linhas referentes a um único áudio\n",
    "\t\tdataframeArquivoSelecionado = dataframe.loc[dataframe[dataframe.columns[0]] == arquivo]\n",
    "\t\treturn dataframeArquivoSelecionado\n",
    "\n",
    "\tdef obterYRealYPredUnicoAudio(self, dataframeUnicoAudio, classificador):\n",
    "\t\t# Função para predizer um único áudio e retornar as classificações real e predita\n",
    "\t\t# Pois bem, já temos a função de predizer um único áudio, mas ela precisa receber ua matriz bonitinha que só contenha features e que não seja do tipo pandas.\n",
    "\t\t# A função proposta agora deve receber o dataframe tipo pandas de um único áudio, separar o que é xTest e o que é yReal, mandar classificar xTest e devolver yReal e yPred.\n",
    "\n",
    "\t\t# PRIMEIRO EU SEPARO O QUE E X E Y\n",
    "\t\txTest, arrayYReal = self.separarDataframeXeY(dataframeUnicoAudio)\n",
    "\t\t\n",
    "\t\t# FACO YREAL SER UM VALOR UNICO JA QUE A FUNCAO ACIMA RETORNA UM ARRAY Y\n",
    "\t\tyReal = arrayYReal[0]\n",
    "\t\t\n",
    "\t\t# PREDIZENDO A CLASSE DO AUDIO EM QUESTAO (A FUNCAO ABAIXO JA RETORNA A MODA)\n",
    "\t\tyPred = self.predizerUnicoAudio(xTest, classificador)\n",
    "\t\t\n",
    "\t\treturn yReal, yPred  \n",
    "\n",
    "\tdef classificarDataframeCompleto(self, dataframeTeste, classificador, verbose=False):\n",
    "\t\t# Função para classificar um dataframe de teste inteiro\n",
    "\t\t# A função abaixo vai receber um dataframe e um classificador. Depois disso ela vai:\n",
    "\t\t# 1) Obter um array com o nome dos arquivos desse dataframe utilizando a função obterNomesArquivos;\n",
    "\t\t# 2) Para cada arquivo no dataframe, ela vai criar um novo dataframe contendo as janelas apenas desse único áudio, utilizando, para isso, a função obterDataframeUnicoAudio;\n",
    "\t\t# 3) Obter a classificação real e a predita para cada um dos arquivos utilizando a função obterYRealYPredUnicoAudio;\n",
    "\t\t# 4) Com tudo isso, ela vai montar os arrays yTest e yPred;\n",
    "\t\t# 5) Retornar o classification report do sklearn como um DICT (depois fica bem facil de transformar em JSON) com todas as informações de precisão, recall, acurácia e tal.\n",
    "\t\t# A função que vai salvar o classification report, convertendo-o para um JSON será implementada a diante. Lembrando que essa função também vai ficar responsável por colocar o nome do classificador utilizado no classification report.\n",
    "\t\t\n",
    "\t\tprint(\"Classificando com o \", classificador.__class__.__name__)\n",
    "\t\t\n",
    "\t\t# CRIANDO OS ARRAYS GERAIS\n",
    "\t\tyRealCadaAudio = []\n",
    "\t\tyPredCadaAudio = []\n",
    "\t\t\n",
    "\t\t# PEGANDO O NOME DOS ARQUIVOS QUE ESTAO NO DATAFRAME\n",
    "\t\tarrayNomesArquivos = self.obterNomesArquivos(dataframeTeste)\n",
    "\t\ttotalArquivos = len(arrayNomesArquivos)\n",
    "\t\t\n",
    "\t\t# PARA CADA ARQUIVO NO DATAFRAME DE TESTE\n",
    "\t\tfor i, arquivo in enumerate(arrayNomesArquivos):\n",
    "\t\t\t\n",
    "\t\t\tif verbose == True:\n",
    "\t\t\t\tprint(\"Classificando \" + arquivo + \". Arquivo\", i+1, \"de\", totalArquivos, \"->\", str(100*((i+1)/totalArquivos))+\"%\")\n",
    "\t\t\t\n",
    "\t\t\t# EU CRIO UM DATAFRAME CONTENDO APENAS AS LINHAS DO AUDIO ATUAL\n",
    "\t\t\tdataframeAudioAtual = self.obterDataframeUnicoAudio(dataframeTeste, arquivo)\n",
    "\t\t\t\n",
    "\t\t\t# E OBTENHO, PARA ESSE AUDIO, A CLASSIFICACAO REAL E A PREDITA\n",
    "\t\t\tyRealAtual, yPredAtual = self.obterYRealYPredUnicoAudio(dataframeAudioAtual, classificador)\n",
    "\t\t\t\n",
    "\t\t\t# COLOCO O RESULTADO NOS ARRAYS GERAIS\n",
    "\t\t\tyRealCadaAudio.append(yRealAtual)\n",
    "\t\t\tyPredCadaAudio.append(yPredAtual)\n",
    "\t\t\t\n",
    "\t\t# CRIANDO O CLASSIFICATION REPORT. PARA FAZER ELE PARECER UM JSON, TEM QUE COLOCAR output_dict=True\n",
    "\t\t# ASSIM ELE RETORNA UM DICT QUE DEPOIS VAI SER CONVERTIDO PRA JSON E SER SALVO EM ALGUM LUGAR\n",
    "\t\tdictRelatorio = classification_report(yRealCadaAudio, yPredCadaAudio, digits=3, output_dict=True)\n",
    "\t\t\n",
    "\t\t# COLOCANDO O NOME DO CLASSIFICADOR NO DICIONARIO\n",
    "\t\tdictRelatorio['classificador'] = classificador.__class__.__name__\n",
    "\t\t\n",
    "\t\treturn dictRelatorio\n",
    "\n",
    "\tdef salvarRelatorioClassificacao(self, dictRelatorio, diretorioOndeSalvar, nomeDatasetTreino):\n",
    "\t\t# Função para salvar o classification report\n",
    "\t\t# Essa função vai receber um classification report como um DICT, converte-lo para JSON e salvar num diretório. Dentro desse dicionário já vai vir escrito qual foi o classificador utilizado, pois a função classificarDataframeCompleto coloca essa informação antes de retornar esse dicionário do relatório de classificação.\n",
    "\t\tnomeJSON = \"relatorio_\" + nomeDatasetTreino + \"_\" + str(time.time()) + \".json\"\n",
    "\t\t\n",
    "\t\tprint(\"Salvando as informações num JSON:\", nomeJSON)\n",
    "\t\t\n",
    "\t\twith open(diretorioOndeSalvar + nomeJSON, 'w') as json_file:\n",
    "\t\t\tjson.dump(dictRelatorio, json_file)\n",
    "\n",
    "\tdef classificarDataframe(self, dataframeTeste, arrayObjClassificadores, diretorioOndeSalvar, nomeDatasetTreino, verbose=False):\n",
    "\t\t# Função para classificar um dataset com todos os classificadores e gerar os relatorios\n",
    "\t\t# Essa é a função principal da parte de treinamento de dataset, pois ela vai receber um dataset e o array de classificadores já treinados e, para cada classificador, ela vai garar um relátorio de classificação.\n",
    "\t\tprint(\"Começando a classificar o dataset\", nomeDatasetTreino)\n",
    "\t\t\n",
    "\t\t# PARA CADA CLASSIFICADOR\n",
    "\t\tfor classificadorAtual in arrayObjClassificadores:\n",
    "\t\t\t\n",
    "\t\t\t# EU GERO O RELATORIO DE CLASSIFICACAO COMO UM DICIONARIO\n",
    "\t\t\tdictRelatorioAtual = self.classificarDataframeCompleto(dataframeTeste, classificadorAtual, verbose)\n",
    "\n",
    "\t\t\tprint(\"Acurácia:\", dictRelatorioAtual[\"accuracy\"])\n",
    "\t\t\t\n",
    "\t\t\t# E SALVO AS INFORMACOES COMO JSON\n",
    "\t\t\tself.salvarRelatorioClassificacao(dictRelatorioAtual, diretorioOndeSalvar, nomeDatasetTreino)\n",
    "\n",
    "\t\tprint(\"O teste com todos os classificadores foi finalizado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando a classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Crie o caminho para o CSV de TREINAMENTO e abra-o como um pandas dataframe;\n",
    "\n",
    "2) Utilizando o dataframe de treinamento aberto, crie e treine os classificadores desejados;\n",
    "\n",
    "3) Crie o caminho para o CSV de TESTE, setando as váriaveis diretorio e nomeDataset;\n",
    "\n",
    "4) Classifique o dataset de TESTE aberto, especificando onde o JSON do relátorio deve ser salvo\n",
    "\n",
    "Os passos 3 e 4 podem ser repetidos caso se deseje classificar vários datasets de TESTE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Começando o treinamento dos classificadores\n",
      "Instanciando o 1º objeto da classe KNeighborsClassifier()\n",
      "Instanciando o 2º objeto da classe KNeighborsClassifier()\n",
      "Instanciando o 3º objeto da classe KNeighborsClassifier()\n",
      "Instanciando o 4º objeto da classe KNeighborsClassifier()\n",
      "Instanciando o 5º objeto da classe KNeighborsClassifier()\n",
      "Tempo de treinamento do KNeighborsClassifier (segundos): 0.03890275955200195\n",
      "Tempo de treinamento do KNeighborsClassifier (segundos): 0.05088186264038086\n",
      "Tempo de treinamento do KNeighborsClassifier (segundos): 0.03862953186035156\n",
      "Tempo de treinamento do KNeighborsClassifier (segundos): 0.03982734680175781\n",
      "Tempo de treinamento do KNeighborsClassifier (segundos): 0.038634300231933594\n",
      "Classificadores treinados\n",
      "Começando a classificar o dataset teste_normalizado_semPCA\n",
      "Classificando com o  KNeighborsClassifier\n",
      "Acurácia: 0.8476190476190476\n",
      "Salvando as informações num JSON: relatorio_teste_normalizado_semPCA_1581552922.1057143.json\n",
      "Classificando com o  KNeighborsClassifier\n",
      "Acurácia: 0.8571428571428571\n",
      "Salvando as informações num JSON: relatorio_teste_normalizado_semPCA_1581552924.1730502.json\n",
      "Classificando com o  KNeighborsClassifier\n",
      "Acurácia: 0.8666666666666667\n",
      "Salvando as informações num JSON: relatorio_teste_normalizado_semPCA_1581552926.2879748.json\n",
      "Classificando com o  KNeighborsClassifier\n",
      "Acurácia: 0.8761904761904762\n",
      "Salvando as informações num JSON: relatorio_teste_normalizado_semPCA_1581552928.4928098.json\n",
      "Classificando com o  KNeighborsClassifier\n",
      "Acurácia: 0.819047619047619\n",
      "Salvando as informações num JSON: relatorio_teste_normalizado_semPCA_1581552930.6492019.json\n",
      "O teste com todos os classificadores foi finalizado\n"
     ]
    }
   ],
   "source": [
    "objTreinarEClassificar = TreinarEClassificar()\n",
    "\n",
    "# ABRINDO O CSV DE TREINO COM PANDAS\n",
    "caminhoCSVTreino = '/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/train/treino_normalizado_semPCA.csv'\n",
    "dataframeTreino = pd.read_csv(caminhoCSVTreino) \n",
    "\n",
    "# CRIANDO E TREINANDO OS CLASIFICADORES\n",
    "arrayStringsClassificadores = [\"KNeighborsClassifier()\"]\n",
    "arrayObjClassificadores = objTreinarEClassificar.criarETreinarClassificadores(dataframeTreino, arrayStringsClassificadores, kCrossValidation=5, percentual=0.75, verbose=True)\n",
    "\n",
    "# ABRINDO O CSV QUE EU DESEJO CLASSIFICAR - DATASET DE TESTE \n",
    "diretorio         = '/home/dimi/Programming/IC2019/ML/datasets/SESA/SESA_Normalizado/test/'\n",
    "nomeDatasetTreino = 'teste_normalizado_semPCA'\n",
    "caminhoCSVTeste   = diretorio + nomeDatasetTreino + '.csv'\n",
    "dataframeTeste    = pd.read_csv(caminhoCSVTeste)\n",
    "\n",
    "# CLASSIFICANDO O DATAFRAME DE TESTE\n",
    "objTreinarEClassificar.classificarDataframe(dataframeTeste, arrayObjClassificadores, diretorio, nomeDatasetTreino, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
