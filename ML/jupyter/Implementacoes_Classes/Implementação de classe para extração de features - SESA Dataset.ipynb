{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRIAÇÃO DA CLASSE DE EXTRAÇÃO DE FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse jupyter tem como objetivo implementar o maior número possível de funções para extração de features. Essas funções serão testadas para que depois possa ser criada uma classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamanho do janelamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É preciso analisar o dataset para verificar qual vai ser o tamanho do janelamento. Para garantir que o processamento seja o mais rápido possível, o tamanho da janela será o tamanho do menor áudio.\n",
    "\n",
    "As células abaixo verificarão qual é o tamanho do menor arquivo do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayDuracoes = []\n",
    "\n",
    "diretorio = \"/home/dimi/Downloads/SESA/test/\"\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    arrayDuracoes.append(librosa.get_duration(filename=diretorio + arquivo))\n",
    "\n",
    "diretorio = \"/home/dimi/Downloads/SESA/train/\"\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    arrayDuracoes.append(librosa.get_duration(filename=diretorio + arquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Duração mínima:\", min(arrayDuracoes))\n",
    "print(\"Duração máxima:\", max(arrayDuracoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixo vai setar o valor da variável do janelamento. FRAME_TIME e OVERLAP_TIME estarão em segundos, já FRAME_LENGTH e OVERLAP_LENGTH estarão em amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequência de amostragem do dataset:\t 16000\n",
      "Tamanho do janelamento (amostras):\t 17145\n"
     ]
    }
   ],
   "source": [
    "audioTesteDir = \"/home/dimi/Downloads/Datasets/SESA/SESA_Normalizado/test/casual_015.wav\" \n",
    "audioTeste, freqAmostragem = librosa.load(audioTesteDir, sr=None, mono=True)\n",
    "\n",
    "# frameTime     = min(arrayDuracoes)\n",
    "# overlapTime   = frameTime / 2\n",
    "\n",
    "# frameLength   = int(freqAmostragem * frameTime)\n",
    "# overlapLength = int(freqAmostragem * overlapTime)\n",
    "\n",
    "frameLength    = 17145\n",
    "overlapLength  = 8572\n",
    "\n",
    "print(\"Frequência de amostragem do dataset:\\t\", freqAmostragem)\n",
    "print(\"Tamanho do janelamento (amostras):\\t\", frameLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando e testando as funções que vão extrair as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar as funções, vou utilizar um áudio qualquer, que já foi definido na célula anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do áudio teste (amostras):\t 59443\n",
      "Tamanho do janelamento (amostras):\t 17145\n",
      "\n",
      "Qtd de janelas do áudio de teste:\t 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho do áudio teste (amostras):\\t\", len(audioTeste))\n",
    "print(\"Tamanho do janelamento (amostras):\\t\", frameLength)\n",
    "\n",
    "# PARA SABER O NÚMERO DE JANELAS, TENHO QUE MULTIPLICAR POR 2 ALÍ PQ AINDA TEM A SOBREPOSIÇÃO\n",
    "# E SOMAR UM PQ SEMPRE VAI SOBRAR UM TECO\n",
    "print(\"\\nQtd de janelas do áudio de teste:\\t\", 1 + 2*int(len(audioTeste)/frameLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features unitárias por janela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vou criar as funções para extrair as features que retornam somente um valor para cada janela do áudio. Vou deixar MFCCs, Chromas e Contrastes pra depois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairRMS(sinal, frameLength, overlapLength):\n",
    "    return librosa.feature.rms(y=sinal, frame_length=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[1.8244174  1.7309765  1.2711647  0.64006954 0.4016891  0.21991439\n",
      "  0.1802007 ]]\n"
     ]
    }
   ],
   "source": [
    "rms = extrairRMS(audioTeste, frameLength, overlapLength)\n",
    "print(\"Total:\", len(rms[0]))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centróide Espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairCentroideEspectral(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    return librosa.feature.spectral_centroid(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[1707.30728685 1970.68697732 1777.47750879 1628.37444789 1595.59947744\n",
      "  1651.58124723 1589.94796039]]\n"
     ]
    }
   ],
   "source": [
    "centroideEspectral = extrairCentroideEspectral(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(\"Total:\", len(centroideEspectral[0]))\n",
    "print(centroideEspectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Largura de banda espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairLarguraBanda(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    return librosa.feature.spectral_bandwidth(y=sinal, sr= freqAmostragem, n_fft=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[1769.53946856 1796.04157924 1652.75762193 1556.0451078  1638.72081291\n",
      "  1831.41487789 2008.99462475]]\n"
     ]
    }
   ],
   "source": [
    "larguraBanda = extrairLarguraBanda(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(\"Total:\", len(larguraBanda[0]))\n",
    "print(larguraBanda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planicidade espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairPlanicidade(sinal, frameLength, overlapLength):\n",
    "    return librosa.feature.spectral_flatness(y=sinal, n_fft=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[0.02452501 0.08477717 0.05941166 0.04232679 0.04525724 0.04924234\n",
      "  0.03320206]]\n"
     ]
    }
   ],
   "source": [
    "planicidade = extrairPlanicidade(audioTeste, frameLength, overlapLength)\n",
    "print(\"Total:\", len(planicidade[0]))\n",
    "print(planicidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rolloff espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairRolloff(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    return librosa.feature.spectral_rolloff(y=sinal, sr= freqAmostragem, n_fft=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[3749.88334111 4061.59589361 3585.62762483 3187.12085861 3118.9920672\n",
      "  3328.04479701 3695.75361643]]\n"
     ]
    }
   ],
   "source": [
    "rolloff = extrairRolloff(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(\"Total:\", len(rolloff[0]))\n",
    "print(rolloff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxa de cruzamentos por zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairZCR(sinal, frameLength, overlapLength):\n",
    "    return librosa.feature.zero_crossing_rate(y=sinal, frame_length=frameLength, hop_length=overlapLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7\n",
      "[[0.06310878 0.14237387 0.15263925 0.13957422 0.12015165 0.09932925\n",
      "  0.07588218]]\n"
     ]
    }
   ],
   "source": [
    "zcr = extrairZCR(audioTeste, frameLength, overlapLength)\n",
    "print(\"Total:\", len(zcr[0]))\n",
    "print(zcr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features não unitárias por janela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim é hora de extrair os MFCCs, Chromas e Contrastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função do MFCC retorna uma matriz, e ela será necessária para calcular os deltas e delta deltas, mas, na verdade, o MFCC que será colocado no array de features é uma média de cada linha da matriz. Por isso, primeiro vamos criar uma matriz do MFCC, e só depois a função extrairMediaMFCC vai fazer a média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairMatrizMFCC(sinal, freqAmostragem):\n",
    "    return librosa.feature.mfcc(y=sinal, sr=freqAmostragem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd linhas (MFCCs): 20\n",
      "Qtd de valores em cada linha: 117\n"
     ]
    }
   ],
   "source": [
    "matrizMFCC = extrairMatrizMFCC(audioTeste, freqAmostragem)\n",
    "\n",
    "print(\"Qtd linhas (MFCCs):\", len(matrizMFCC))\n",
    "print(\"Qtd de valores em cada linha:\", len(matrizMFCC[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairMFCCs(matrizMFCC):\n",
    "    \n",
    "    arrayMFCCs = []\n",
    "    \n",
    "    for linha in matrizMFCC:\n",
    "        arrayMFCCs.append(np.mean(linha))\n",
    "        \n",
    "    return arrayMFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de MFCCs: 20\n",
      "[90.35726, 96.21592, -12.690334, 23.92078, 3.9557667, 9.098954, -1.1837934, 1.7929257, -3.8612175, 2.1821105, -1.5066134, 1.5684648, -2.1820452, -0.8958572, -5.939487, -2.4142895, -2.9936216, -0.32899868, -1.2340535, -0.96812487]\n"
     ]
    }
   ],
   "source": [
    "MFCCs = extrairMFCCs(matrizMFCC)\n",
    "\n",
    "print(\"Qtd de MFCCs:\", len(MFCCs))\n",
    "print(MFCCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como o MFCC, a função do librosa que extrai os deltas retorna uma matriz. A função abaixo retorna a média de cada linha dessa matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairDeltas(matrizMFCC):\n",
    "    matrizDelta = librosa.feature.delta(matrizMFCC, order=1)\n",
    "\n",
    "    arrayDelta = []\n",
    "\n",
    "    for linha in matrizDelta:\n",
    "        arrayDelta.append(np.mean(linha))\n",
    "\n",
    "    return arrayDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de deltas: 20\n",
      "[1.2634532, 0.2583152, -0.18495567, -0.121523894, -0.084837, -0.056756202, -0.15059838, -0.0023076106, 0.008575201, 0.014145123, -0.09964522, -0.036289196, -0.025149047, -0.005005702, -0.01031554, -0.0028545063, -0.020311967, 0.08247934, 0.026181314, 0.00038621976]\n"
     ]
    }
   ],
   "source": [
    "deltas = extrairDeltas(matrizMFCC)\n",
    "\n",
    "print(\"Qtd de deltas:\", len(deltas))\n",
    "print(deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC Delta Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairDeltaDeltas(matrizMFCC):\n",
    "    matrizDeltaDelta = librosa.feature.delta(matrizMFCC, order=2)\n",
    "\n",
    "    arrayDeltaDelta = []\n",
    "\n",
    "    for linha in matrizDeltaDelta:\n",
    "        arrayDeltaDelta.append(np.mean(linha))\n",
    "\n",
    "    return arrayDeltaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de delta deltas: 20\n",
      "[0.4892378, -0.021952502, -0.043641336, 0.044424415, 0.0073836413, 0.045231894, -0.0027372497, -0.009363727, -0.027617775, 0.032582693, 0.008763685, -0.009184939, -0.02254185, 0.0071497113, -0.008626881, 0.030296305, -0.00078415044, -0.032558195, -0.054833964, -0.0201306]\n"
     ]
    }
   ],
   "source": [
    "deltaDeltas = extrairDeltaDeltas(matrizMFCC)\n",
    "\n",
    "print(\"Qtd de delta deltas:\", len(deltaDeltas))\n",
    "print(deltaDeltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel Espectrograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa também retorna uma matriz, mas ela vem invertida, tenho que tirar a média de cada COLUNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairMelEspectrograma(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    \n",
    "    matrizMelEspectrograma = librosa.feature.melspectrogram(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "    \n",
    "    arrayMelEspectrograma = []\n",
    "    \n",
    "    for coluna in matrizMelEspectrograma.T:\n",
    "        arrayMelEspectrograma.append(np.mean(coluna))\n",
    "    \n",
    "    return arrayMelEspectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de features: 7\n",
      "[19364.988, 72401.11, 14928.781, 7237.6953, 1758.3064, 666.27026, 586.1963]\n"
     ]
    }
   ],
   "source": [
    "melEspectrograma = extrairMelEspectrograma(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "\n",
    "print(\"Qtd de features:\", len(melEspectrograma))\n",
    "print(melEspectrograma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cromagrama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa também retorna uma matriz. Ela tem 12 cromagramas (linhas). Vou tirar a média de cada linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairCromagramas(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    \n",
    "    matrizCromagramas = librosa.feature.chroma_stft(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "    \n",
    "    arrayCromagramas = []\n",
    "    \n",
    "    for linha in matrizCromagramas:\n",
    "        arrayCromagramas.append(np.mean(linha))\n",
    "    \n",
    "    return arrayCromagramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 12\n",
      "[0.7875995, 0.789555, 0.75121117, 0.69452906, 0.7602438, 0.8831463, 0.82073545, 0.8278985, 0.76663816, 0.73204404, 0.79973537, 0.7402423]\n"
     ]
    }
   ],
   "source": [
    "cromagramas = extrairCromagramas(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(\"Features:\", len(cromagramas))\n",
    "print(cromagramas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cromagrama de constante Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função não precisa do tamanho da janela (frameLength) e a sobreposição: \"hop_length must be a positive integer multiple of 2^6 for 7-octave CQT\". Portanto, vou deixar esse parâmetro como padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairCromagramasQ(sinal, freqAmostragem):\n",
    "    \n",
    "    matrizCromagramasQ = librosa.feature.chroma_cqt(y=sinal, sr=freqAmostragem)\n",
    "    \n",
    "    arrayCromagramasQ = []\n",
    "    \n",
    "    for linha in matrizCromagramasQ:\n",
    "        arrayCromagramasQ.append(np.mean(linha))\n",
    "    \n",
    "    return arrayCromagramasQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 12\n",
      "[0.7928085000434514, 0.7942605753931457, 0.7598130786874815, 0.738256730346462, 0.7696198297598498, 0.7740035970465032, 0.7500368186214228, 0.7563676292237278, 0.6885176645831349, 0.632005522003134, 0.6410327953833604, 0.5981624320001039]\n"
     ]
    }
   ],
   "source": [
    "cromagramasQ = extrairCromagramasQ(audioTeste, freqAmostragem)\n",
    "print(\"Features:\", len(cromagramasQ))\n",
    "print(cromagramasQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Croma CENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como o cromagrama de constante Q, essa função não precisa do tamanho da janela (frameLength) e a sobreposição: \"hop_length must be a positive integer multiple of 2^6 for 7-octave CQT\". Portanto, vou deixar esse parâmetro como padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairCromaCENSs(sinal, freqAmostragem):\n",
    "    \n",
    "    matrizCromaCENSs = librosa.feature.chroma_cens(y=sinal, sr=freqAmostragem)\n",
    "    \n",
    "    arrayCromaCENSs = []\n",
    "    \n",
    "    for linha in matrizCromaCENSs:\n",
    "        arrayCromaCENSs.append(np.mean(linha))\n",
    "    \n",
    "    return arrayCromaCENSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 12\n",
      "[0.33069522167624155, 0.32728316903120086, 0.29582167844150786, 0.29450791898182055, 0.3111067782230877, 0.3072401050430688, 0.296477005846955, 0.2942989525684849, 0.2671905424505684, 0.23553858905577774, 0.24617813448804013, 0.21002142719909053]\n"
     ]
    }
   ],
   "source": [
    "cromaCENSs = extrairCromaCENSs(audioTeste, freqAmostragem)\n",
    "print(\"Features:\", len(cromaCENSs))\n",
    "print(cromaCENSs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contraste espectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ultimas features serão essas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairContrastes(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    \n",
    "    matrizContrastes = librosa.feature.spectral_contrast(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "    \n",
    "    arrayConstrastes = []\n",
    "    \n",
    "    for linha in matrizContrastes:\n",
    "        arrayConstrastes.append(np.mean(linha))\n",
    "    \n",
    "    return arrayConstrastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.187328876949742, 15.745184288522415, 15.827735450971762, 15.369437040530203, 16.12093632251706, 17.10694956632393, 16.748398695995743]\n"
     ]
    }
   ],
   "source": [
    "contrastes = extrairContrastes(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(contrastes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairTonnetz(sinal, freqAmostragem):\n",
    "    \n",
    "    matrizTonnetz = librosa.feature.tonnetz(y=sinal, sr=freqAmostragem)\n",
    "\n",
    "    arrayTonnetz = []\n",
    "\n",
    "    for linha in matrizTonnetz:\n",
    "        arrayTonnetz.append(np.mean(linha))\n",
    "\n",
    "    return arrayTonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.004656962928969554,\n",
       " 0.015397312645967883,\n",
       " -0.011890796281157972,\n",
       " 0.0119155427492697,\n",
       " 0.007296877893321908,\n",
       " 0.0014926964149470884]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrairTonnetz(audioTeste, freqAmostragem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é que essa classe entre numa pasta e me devolva uma matriz em que cada linha seja um áudio e cada coluna seja uma feature. Essa classe ainda deve ser capaz de gravar tudo isso num csv.\n",
    "\n",
    "As features serão extraídas, e depois que tudo já estiver pronto, ela vai escalonar as features e depois passar tudo num PCA.\n",
    "\n",
    "Então, para usar a classe, é necessário ter as pastas de áudios muito bem organizadas para que ela crie o CSV dentro da pasta que se queira. Preferi fazer assim, pois, se eu fosse abrir todos os áudios numa matriz do python pra só depois mandar pra essa classe, poderia ficar mto pesado. É melhor que ela só receba o caminho pra uma pasta e gere um CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando funções intermediárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou usar essa parte pra criar as funções intermediárias, que não serão responsáveis por calcular nenhuma feature, mas apenas montar os arrays e metrizes da classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que faz o janelamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe um problema em deixar que as funções de extração de features criadas acima façam o janelamento: ao invés de retornarem valores unitários para as features, elas vão retornar um array em que cada posição representa um janelamento. Portanto, a solução é fazer o janelamento antes de extrair as features e deixar para mandar para essas funções apenas as janelas, fazendo com que frameLength seja igual ao tamanho da janela que está sendo enviada e que overlapLength seja 0.\n",
    "\n",
    "A função abaixo usa a função frame do librosa que retorna as janelas como COLUNAS. Como eu quero que cada janela seja uma LINHA, eu retorno a transposta dessa função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fazerJanelamento(sinal, frameLength, overlapLength):\n",
    "    return librosa.util.frame(sinal, frame_length=frameLength, hop_length=overlapLength).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framesAudioTeste = fazerJanelamento(audioTeste, frameLength, overlapLength)\n",
    "print(\"Qtd janelas:\", len(framesAudioTeste))\n",
    "print(framesAudioTeste)\n",
    "print(framesAudioTeste[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=framesAudioTeste[0], rate=freqAmostragem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que extrai features de um único frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em algum momento, a classe deverá passar em cada um dos áudios da pasta para ir extraindo as features. A próxima função extrai as features de um único frame de áudio e retorna um array com essas features. Posteriormente esse array deverá ser integrado à matriz de features de todos os áudios.\n",
    "\n",
    "Haverá uma outra função para extrair as features de um único áudio. Ela deverá pegar um áudio, usar a função de janelamento, e usar a função abaixo para extrair as features de cada uma das janelas. Depois, ela vai retornar uma matriz com as features de cada frame de um único áudio.\n",
    "\n",
    "PARA IMPEDIR QUE O LIBROSA CONTINUE FAZENDO O JANELAMENTO DO ÁUDIO MESMO QUE frameLength SEJA DO TAMANHO DO ÁUDIO, O PARÂMETRO DE OVERLAP DEVE SER MAIOR OU IGUAL A frameLength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairFeaturesUnicoFrame(sinal, freqAmostragem, frameLength):\n",
    "    \n",
    "    # PARA IMPEDIR QUE O LIBROSA CONTINUE FAZENDO O JANELAMENTO DO ÁUDIO MESMO QUE frameLength \n",
    "    # SEJA DO TAMANHO DO ÁUDIO, O PARÂMETRO DE OVERLAP DEVE SER MAIOR OU IGUAL A frameLength:\n",
    "    overlapLength = frameLength\n",
    "    \n",
    "    # CRIANDO O ARRAY DE FEATURES DO FRAME EM QUESTAO\n",
    "    arrayFeaturesFrame = []\n",
    "    \n",
    "    #PRIMEIRO, VOU EXTRAIR AS FEATURES UNITARIAS\n",
    "    arrayFeaturesFrame.append(float(extrairRMS(sinal, frameLength, overlapLength)))\n",
    "    arrayFeaturesFrame.append(float(extrairCentroideEspectral(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "    arrayFeaturesFrame.append(float(extrairLarguraBanda(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "    arrayFeaturesFrame.append(float(extrairPlanicidade(sinal, frameLength, overlapLength)))\n",
    "    arrayFeaturesFrame.append(float(extrairRolloff(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "    arrayFeaturesFrame.append(float(extrairZCR(sinal, frameLength, overlapLength)))\n",
    "    \n",
    "    # AGORA VAMOS PASSAR PARA AS NAO UNITARIAS, PRIMEIRO, E PRECISO CRIAR A MATRIZ DOS MFCCS\n",
    "    matrizMFCC          = extrairMatrizMFCC(sinal, freqAmostragem)\n",
    "    \n",
    "    # AGORA SIM EU SAIO EXTRAINDO AS FEATURES \n",
    "    arrayFeaturesFrame += extrairMFCCs(matrizMFCC)\n",
    "    arrayFeaturesFrame += extrairDeltas(matrizMFCC)\n",
    "    arrayFeaturesFrame += extrairDeltaDeltas(matrizMFCC)\n",
    "    arrayFeaturesFrame += extrairMelEspectrograma(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "    arrayFeaturesFrame += extrairCromagramas(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "    arrayFeaturesFrame += extrairCromagramasQ(sinal, freqAmostragem)\n",
    "    arrayFeaturesFrame += extrairCromaCENSs(sinal, freqAmostragem)\n",
    "    arrayFeaturesFrame += extrairContrastes(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "    \n",
    "    # POR FIM, RETORNO O ARRAY DE FEATURES DO AUDIO QUE FOI ENVIADO PARA ESSA FUNCAO\n",
    "    return arrayFeaturesFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameAtual = framesAudioTeste[0]\n",
    "\n",
    "featuresFrameAtual = extrairFeaturesUnicoFrame(frameAtual, freqAmostragem, frameLength)\n",
    "\n",
    "print(len(featuresFrameAtual))\n",
    "print(featuresFrameAtual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que extrai as features de um único áudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função vai pegar um áudio, usar a função de janelamento, e para cada janela do áudio em questão, ela vai usar a função de extrair as features de uma única janela (implementada acima). Depois, ela vai retornar uma matriz com as features de cada frame de um único áudio, onde cada linha é uma frame e cada coluna é uma feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrairFeaturesUnicoAudio(sinal, freqAmostragem, frameLength, overlapLength):\n",
    "    \n",
    "    # PRIMEIRO, VOU CRIAR A MATRIZ QUE VAI CONTER AS FEATURES DE CADA JANELA\n",
    "    # CADA LINHA E UMA JANELA E CADA COLUNA E UMA FEATURE\n",
    "    matrizFeaturesAudio = []\n",
    "    \n",
    "    # DEPOIS, VOU FAZER O JANELAMENTO\n",
    "    matrizFramesAudio = fazerJanelamento(sinal, frameLength, overlapLength)\n",
    "    \n",
    "    # AGORA, PARA CADA JANELA, VOU EXTRAIR AS FEATURES E COLOCAR COMO UMA LINHA NOVA NA MATRIZ\n",
    "    for frameAtual in matrizFramesAudio:\n",
    "        matrizFeaturesAudio.append(extrairFeaturesUnicoFrame(frameAtual, freqAmostragem, frameLength))\n",
    "    \n",
    "    # RETORNO A MATRIZ DE FEATURES DESSE AUDIO\n",
    "    return matrizFeaturesAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrizFeaturesAudioTeste = extrairFeaturesUnicoAudio(audioTeste, freqAmostragem, frameLength, overlapLength)\n",
    "print(\"Qtd frames (linhas):\", len(matrizFeaturesAudioTeste))\n",
    "print(\"Qtd features (colunas):\", len(matrizFeaturesAudioTeste[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que coloca o nome do arquivo e a classificação correta na matriz de features de um áudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haverá uma matriz de dados que terá as seguintes colunas: **nomeArquivo, ...features... e classificacaoCorreta**. Mas, a função implementada para gerar a matriz de features de um único áudio **extrairFeaturesUnicoAudio** devolve uma matriz de features **sem** o nome do áudio e a classificação correta. Portanto, a função abaixo apenas pega essa última matriz e coloca o nome do arquivo no começo e a classificação correta ao final. Posteriormente, o resultado será agregado à matriz de dados citada em primeiro lugar.\n",
    "\n",
    "ESSA FUNÇÃO RETORNA UM DATAFRAME PANDAS, NÃO UMA MATRIZ QUALQUER.\n",
    "\n",
    "https://www.geeksforgeeks.org/python-pandas-dataframe-insert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adicionarNomeArquivoEClasse(matrizFeaturesAudioAtual, nomeArquivo, classificacaoCorreta):\n",
    "    # PRIMEIRO TRANSFORMO A MATRIZ NUM PANDAS DATAFRAME\n",
    "    dataframeAudioAtual = pd.DataFrame(matrizFeaturesAudioAtual)\n",
    "    \n",
    "    # AGORA COLOCO A COLUNA DO NOME NO COMECO (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "    dataframeAudioAtual.insert(0, \"nomeArquivo\", nomeArquivo, True)\n",
    "    \n",
    "    # AGORA COLOCO A COLUNA DA CLASSIFICACAO CORRETA NA ULTIMA POSICAO\n",
    "    dataframeAudioAtual.insert(len(dataframeAudioAtual.columns), \"classificacaoCorreta\", classificacaoCorreta, True)\n",
    "    \n",
    "    return dataframeAudioAtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeAudioTeste = adicionarNomeArquivoEClasse(matrizFeaturesAudioTeste, \"teste.wav\", \"gunshot\")\n",
    "dataframeAudioTeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para verificar qual é a classificação correta de acordo com o nome do arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é bem básica. Em algum determinado momento eu vou precisar saber a classficação correta de um determinado áudio. Eu só consigo saber isso pelo nome do arquivo. LEMBRANDO QUE TODO O CÓDIGO ESCRITO AQUI SERVE PARA O BANCO DE DADOS SESA. Os arquivos são nomeados como **classe_contador.wav**. Por exemplo: casual_000.wav, explosion_032.wav e gunshot_032.wav."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificarClassificacaoCorreta(nomeArquivo):\n",
    "    arrayNome = nomeArquivo.split(\"_\")\n",
    "    return arrayNome[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = \"/home/dimi/Downloads/SESA/test/\"\n",
    "parar = 10\n",
    "for nomeArquivo in os.listdir(diretorio):\n",
    "    print(verificarClassificacaoCorreta(nomeArquivo))\n",
    "    parar -= 1\n",
    "    if parar == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que passa por todos os áudios da pasta e vai montando o dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa é função que une todas as outras. Ela vai passar por todos os áudios da pasta, verificar qual é a classificação correta de cada áudio, extrair as features, gerar o dataframe de features do áudio atual e agregar ao dataframe de todos os áudios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montarDataframeTodosOsAudios(diretorio, freqAmostragem, frameLength, overlapLength):\n",
    "    \n",
    "    print(\"Fora da classe\")\n",
    "    \n",
    "    # CRIANDO O ARRAY COM O NOME DOS ARQUIVOS\n",
    "    arrayNomeArquivos = os.listdir(diretorio)\n",
    "    \n",
    "    # PEGANDO O TOTAL DE ARQUIVOS NA PASTA APENAS PARA FINS DE PRINT\n",
    "    totalArquivosNaPasta = len(arrayNomeArquivos)\n",
    "    \n",
    "    # ABAIXO, VOU CRIAR O DATAFRAME DE TODOS OS AUDIOS\n",
    "    dataframeGeral = pd.DataFrame()\n",
    "\n",
    "    # VOU PASSAR POR TODOS OS AUDIOS DO DIRETORIO\n",
    "    for i, nomeArquivo in enumerate(arrayNomeArquivos):\n",
    "        # PRINTANDO O PROGRESSO\n",
    "        print(\"Extraindo features do arquivo\", i+1, \"de\", totalArquivosNaPasta, \"-> \" + str(100*((i+1)/totalArquivosNaPasta)) + \"%\")\n",
    "        \n",
    "        # ABRO O AUDIO ATUAL COM O LIBROSA\n",
    "        audioAtual, freqAmostragem = librosa.load(audioTesteDir, sr=freqAmostragem, mono=True) \n",
    "        \n",
    "        # VERIFICAO QUAL E A CLASSIFICACAO CORRETA\n",
    "        classeAudioAtual = verificarClassificacaoCorreta(nomeArquivo)\n",
    "        \n",
    "        # MONTO A MATRIZ DE FEATUREA DE CADA FRAME DO AUDIO ATUAL (a funcao abaixo\n",
    "        # devolve uma matriz normal e faz o janelamento em outra funcao tb)\n",
    "        matrizFeaturesAudioAtual = extrairFeaturesUnicoAudio(audioAtual, freqAmostragem, frameLength, overlapLength)\n",
    "        \n",
    "        # AGORA E HORA DE COLOCAR O NOME E A CLASSIFICACAO CORRETA NA MATRIZ\n",
    "        # MAAAS, NA FUNCAO ABAIXO, O BICHO VIRA UM DATAFRAME PANDAS\n",
    "        dataframeAudioAtual      = adicionarNomeArquivoEClasse(matrizFeaturesAudioAtual, nomeArquivo, classeAudioAtual)\n",
    "        \n",
    "        # CONCATENANDO O DATAFRAME DO AUDIO ATUAL AO DATAFRAME GERAL\n",
    "        dataframeGeral = pd.concat([dataframeGeral, dataframeAudioAtual])\n",
    "        \n",
    "    # POR ULTIMO, RETORNO O DATAFRAME GERAL\n",
    "    return dataframeGeral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para escalonar as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função recebe o dataframe geral, remove as primeira e última colunas (nome e classificação), faz o escalonamento e depois coloca as colunas de nome e classificação de volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalonarFeatures(dataframeGeral):\n",
    "    \n",
    "    print(\"Escalonando features\")\n",
    "    \n",
    "    # COPIANDO AS COLUNAS DE NOME E CLASSIFICACAO\n",
    "    colunaArquivo       = dataframeGeral[\"nomeArquivo\"]\n",
    "    colunaClassificacao = dataframeGeral[\"classificacaoCorreta\"]\n",
    "    \n",
    "    # DELETANDO AS COLUNAS ARQUIVO E CLASSIFICACAO\n",
    "    dataframeGeral = dataframeGeral.drop(['nomeArquivo', 'classificacaoCorreta'], axis=1)\n",
    "    \n",
    "    # ESCALONANDO\n",
    "    dataframeGeral = pd.DataFrame(StandardScaler().fit_transform(dataframeGeral))\n",
    "    \n",
    "    # COM ESSA COISA DE TIRA E POE COLUNA, O PANDAS NAO SABE LINDAR COM OS INDEXES,\n",
    "    # ABAIXO EU ESTOU RESETANDO TUDO\n",
    "    colunaArquivo.reset_index(inplace=True, drop=True)\n",
    "    colunaClassificacao.reset_index(inplace=True, drop=True)\n",
    "    dataframeGeral.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # ADICIONANDO AS COLUNAS QUE FORAM EXCLUIDAS (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "    dataframeGeral.insert(0, \"nomeArquivo\", colunaArquivo, True)\n",
    "    dataframeGeral.insert(len(dataframeGeral.columns), \"classificacaoCorreta\", colunaClassificacao, True)\n",
    "    \n",
    "    return dataframeGeral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que reduz a dimensionalidade do dataframe geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de escalonar, vamos reduzir a dimensionalidade utilizando PCA. A ideia é fazer com que o CSV já saia pronto para ser usado, logo, a redução de dimensionalidade deve vir nessa classe. Apesar disso, vou deixar o parâmetro **nDimensoes** lá no construtor da classe, ai caso ele seja nulo eu pulo a parte da redução de dimensionalidade e gero o CSV com todas as features.\n",
    "\n",
    "Poder usar a classe sem fazer a redução de dimensionalidade vai ser muito importante para verificar qual é o melhor número de componentes principais do PCA, como se mostra https://towardsdatascience.com/an-approach-to-choosing-the-number-of-components-in-a-principal-component-analysis-pca-3b9f3d6e73fe\n",
    "\n",
    "Então a ideia é primeiro gerar o CSV completo dos dados de treino, sem reduzir a dimensionalidade, pra depois fazer um estudo sobre o melhor número de componentes principais. Aí sim, com **nDimensoes** definido, eu começo a usar a classe com essa função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduzirDimensionalidade(dataframeGeral, nDimensoes):\n",
    "    \n",
    "    print(\"Reduzindo a dimensionalidade\")\n",
    "    \n",
    "    # COPIANDO AS COLUNAS DE NOME E CLASSIFICACAO\n",
    "    colunaArquivo       = dataframeGeral[\"nomeArquivo\"]\n",
    "    colunaClassificacao = dataframeGeral[\"classificacaoCorreta\"]\n",
    "    \n",
    "    # DELETANDO AS COLUNAS ARQUIVO E CLASSIFICACAO\n",
    "    dataframeGeral = dataframeGeral.drop(['nomeArquivo', 'classificacaoCorreta'], axis=1)\n",
    "    \n",
    "    # REDUZINDO A DIMENSIONALIDADE\n",
    "    dataframeGeral = pd.DataFrame(PCA(n_components=nDimensoes).fit_transform(dataframeGeral))\n",
    "    \n",
    "    # COM ESSA COISA DE TIRA E POE COLUNA, O PANDAS NAO SABE LINDAR COM OS INDEXES,\n",
    "    # ABAIXO EU ESTOU RESETANDO TUDO\n",
    "    colunaArquivo.reset_index(inplace=True, drop=True)\n",
    "    colunaClassificacao.reset_index(inplace=True, drop=True)\n",
    "    dataframeGeral.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # ADICIONANDO AS COLUNAS QUE FORAM EXCLUIDAS (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "    dataframeGeral.insert(0, \"nomeArquivo\", colunaArquivo, True)\n",
    "    dataframeGeral.insert(len(dataframeGeral.columns), \"classificacaoCorreta\", colunaClassificacao, True)\n",
    "    \n",
    "    return dataframeGeral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, vou criar a função que será a construtora da classe (init). Ela vai usar todas as funções que já foram criadas. Depois disso, vai bastar copiar todas as funções pra dentro da classe e fazer acontecer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construtor(diretorio, freqAmostragem, frameLength, overlapLength, nDimensoes=None):\n",
    "    \n",
    "    # PRIMEIRO EU CRIO O DATAFRAME DE TODOS OS AUDIOS DA PASTA\n",
    "    dataframeGeral = montarDataframeTodosOsAudios(diretorio, freqAmostragem, frameLength, overlapLength)\n",
    "    \n",
    "    # DEPOIS EU ESCALONO AS FEATURES\n",
    "    dataframeGeral = escalonarFeatures(dataframeGeral)\n",
    "    \n",
    "    # E AGORA EU REDUZO A DIMENSIONALIDADE\n",
    "    if nDimensoes != None:\n",
    "        dataframeGeral = reduzirDimensionalidade(dataframeGeral, nDimensoes)\n",
    "        \n",
    "    # PARA FINALIZAR, VOU ESCREVER O DATAFRAME NUM CSV\n",
    "    nomeCSV = diretorio + str(time.time()) + \".csv\"\n",
    "    print(\"Escrevendo CSV:\", nomeCSV)\n",
    "    dataframeGeral.to_csv(nomeCSV, index=False)\n",
    "    \n",
    "    # TAMBEM VOU RETORNAR O DATAFRAME, PQ VAI QUE EU PRECISO NE\n",
    "    print(\"Operação finalizada\")\n",
    "    return dataframeGeral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINALMENTE COLOCANDO TUDO DENTRO DA CLASSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira parte vai ter o construtor da classe. A segunda parte vai ser das funções intermediárias que fazem tudo acontecer, e só por último vou colocar as funções de extração de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODA A IMPLEMETACAO DESSA CLASSE ESTA MUITO BEM DOCUMENTADA NO JUPYTER \"\n",
    "# Implementação de classe para extração de features - SESA Dataset\"\n",
    "# VOU COLOCAR O MAXIMO DE COMENTARIOS POSSIVEIS AQUI TAMBEM, MAS PARA MAIS INFORMACOES\n",
    "# E MELHOR OLHAR POR LA\n",
    "\n",
    "# COMO USAR A CLASSE:\n",
    "# A CLASSE ENTRA EM UMA DETERMINADA PASTA CONTENDO APENAS ARQUIVOS WAV E CRIA UM CSV DE FEATURES\n",
    "# A CLASSE TAMBEM E RESPONSAVEL POR ESCALONAR AS FEATURES E FAZER UMA REDUCAO DE DIMENSIONALIDADE\n",
    "\n",
    "# PRIMEIRO, OS PARAMETROS ABAIXOS DEVEM SER SETADOS:\n",
    "# diretorio      -> PASTA ONDE A CLASSE VAI PROCURAR PELOS WAVs PARA GERAR O CSV\n",
    "# freqAmostragem -> A FREQUENCIA DE AMOSTRAGEM DOS AUDIOS DESSA PASTA\n",
    "# frameLength    -> O TAMANHO DAS JANELAS DE CADA AUDIO EM QTD DE FRAMES\n",
    "# overlapLength  -> TAMANHO DA SOBREPOSICAO EM QTD DE FRAMES\n",
    "# nDimensoes     -> QTD DE DIMENSOES UTILIZADAS NO PCA. CASO SEJA NULL, NAO HAVERA REDUCAO DE DIMENSIONALIDADE\n",
    "\n",
    "# O COMANDO ABAIXO INSTANCIA A CLASSE. O CONSTRUTOR DEVOLVE UM DATAFRAME PANDAS AO MESMO TEMPO QUE CRIA O CSV\n",
    "# dataframeGeral = extrairFeatures(diretorio, freqAmostragem, frameLength, overlapLength, nDimensoes)\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class ExtrairFeatures:\n",
    "\n",
    "\t# CONSTRUTOR---------------------------------------------------------------------------------------------\n",
    "\tdef __init__(self, diretorio, freqAmostragem, frameLength, overlapLength, escalonamento=True, nDimensoes=None):    \n",
    "\t\t# PRIMEIRO EU CRIO O DATAFRAME DE TODOS OS AUDIOS DA PASTA\n",
    "\t\tdataframeGeral = self.montarDataframeTodosOsAudios(diretorio, freqAmostragem, frameLength, overlapLength)\n",
    "\t\t\n",
    "\t\t# DEPOIS EU ESCALONO AS FEATURES\n",
    "\t\tif escalonamento == True:\n",
    "\t\t\tdataframeGeral = self.escalonarFeatures(dataframeGeral)\n",
    "\t\t\n",
    "\t\t# E AGORA EU REDUZO A DIMENSIONALIDADE\n",
    "\t\tif nDimensoes != None:\n",
    "\t\t\tdataframeGeral = self.reduzirDimensionalidade(dataframeGeral, nDimensoes)\n",
    "\t\t\t\n",
    "\t\t# PARA FINALIZAR, VOU ESCREVER O DATAFRAME NUM CSV\n",
    "\t\tnomeCSV = diretorio + str(time.time()) + \".csv\"\n",
    "\t\tprint(\"Escrevendo CSV:\", nomeCSV)\n",
    "\t\tdataframeGeral.to_csv(nomeCSV, index=False)\n",
    "\t\t\n",
    "\t\t# TAMBEM VOU RETORNAR O DATAFRAME, PQ VAI QUE EU PRECISO NE\n",
    "\t\tprint(\"Operação finalizada\")\n",
    "\t\t\n",
    "\t\t# return dataframeGeral\n",
    "\n",
    "\t# DEFINICAO DE FUNCOES INTERMEDIARIAS--------------------------------------------------------------------\t\n",
    "\tdef fazerJanelamento(self, sinal, frameLength, overlapLength):\n",
    "\t\t# Função que faz o janelamento\n",
    "\t\t# Existe um problema em deixar que as funções de extração de features criadas acima façam o janelamento: \n",
    "\t\t# ao invés de retornarem valores unitários para as features, elas vão retornar um array em que cada posição \n",
    "\t\t# representa um janelamento. Portanto, a solução é fazer o janelamento antes de extrair as features e deixar \n",
    "\t\t# para mandar para essas funções apenas as janelas, fazendo com que frameLength seja igual ao tamanho da \n",
    "\t\t# janela que está sendo enviada e que overlapLength seja 0.\n",
    "\t\t# A função abaixo usa a função frame do librosa que retorna as janelas como COLUNAS. \n",
    "\t\t# Como eu quero que cada janela seja uma LINHA, eu retorno a transposta dessa função.\n",
    "\t\treturn librosa.util.frame(sinal, frame_length=frameLength, hop_length=overlapLength).T\n",
    "\n",
    "\tdef extrairFeaturesUnicoFrame(self, sinal, freqAmostragem, frameLength):\n",
    "\t\t# Função que extrai features de um único frame\n",
    "\t\t# Em algum momento, a classe deverá passar em cada um dos áudios da pasta para ir extraindo as features. \n",
    "\t\t# A próxima função extrai as features de um único frame de áudio e retorna um array com essas features. \n",
    "\t\t# Posteriormente esse array deverá ser integrado à matriz de features de todos os áudios.\n",
    "\t\t# Haverá uma outra função para extrair as features de um único áudio. Ela deverá pegar um áudio, usar a \n",
    "\t\t# função de janelamento, e usar a função abaixo para extrair as features de cada uma das janelas. Depois, \n",
    "\t\t# ela vai retornar uma matriz com as features de cada frame de um único áudio.\n",
    "\t\t# \n",
    "\t\t# PARA IMPEDIR QUE O LIBROSA CONTINUE FAZENDO O JANELAMENTO DO ÁUDIO MESMO QUE frameLength \n",
    "\t\t# SEJA DO TAMANHO DO ÁUDIO, O PARÂMETRO DE OVERLAP DEVE SER MAIOR OU IGUAL A frameLength.s\n",
    "\t\toverlapLength = frameLength\n",
    "\t\t\n",
    "\t\t# CRIANDO O ARRAY DE FEATURES DO FRAME EM QUESTAO\n",
    "\t\tarrayFeaturesFrame = []\n",
    "\t\t\n",
    "\t\t#PRIMEIRO, VOU EXTRAIR AS FEATURES UNITARIAS\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairRMS(sinal, frameLength, overlapLength)))\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairCentroideEspectral(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairLarguraBanda(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairPlanicidade(sinal, frameLength, overlapLength)))\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairRolloff(sinal, freqAmostragem, frameLength, overlapLength)))\n",
    "\t\tarrayFeaturesFrame.append(float(self.extrairZCR(sinal, frameLength, overlapLength)))\n",
    "\t\t\n",
    "\t\t# AGORA VAMOS PASSAR PARA AS NAO UNITARIAS, PRIMEIRO, E PRECISO CRIAR A MATRIZ DOS MFCCS\n",
    "\t\tmatrizMFCC          = self.extrairMatrizMFCC(sinal, freqAmostragem)\n",
    "\t\t\n",
    "\t\t# AGORA SIM EU SAIO EXTRAINDO AS FEATURES \n",
    "\t\tarrayFeaturesFrame += self.extrairMFCCs(matrizMFCC)\n",
    "\t\tarrayFeaturesFrame += self.extrairDeltas(matrizMFCC)\n",
    "\t\tarrayFeaturesFrame += self.extrairDeltaDeltas(matrizMFCC)\n",
    "\t\tarrayFeaturesFrame += self.extrairMelEspectrograma(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "\t\tarrayFeaturesFrame += self.extrairCromagramas(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "\t\tarrayFeaturesFrame += self.extrairCromagramasQ(sinal, freqAmostragem)\n",
    "\t\tarrayFeaturesFrame += self.extrairCromaCENSs(sinal, freqAmostragem)\n",
    "\t\tarrayFeaturesFrame += self.extrairContrastes(sinal, freqAmostragem, frameLength, overlapLength)\n",
    "\t\t\n",
    "\t\t# POR FIM, RETORNO O ARRAY DE FEATURES DO AUDIO QUE FOI ENVIADO PARA ESSA FUNCAO\n",
    "\t\treturn arrayFeaturesFrame\n",
    "\n",
    "\tdef extrairFeaturesUnicoAudio(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\t# Função que extrai as features de um único áudio\n",
    "\t\t# Essa função vai pegar um áudio, usar a função de janelamento, e para cada janela do áudio em questão, \n",
    "\t\t# ela vai usar a função de extrair as features de uma única janela (implementada acima). \n",
    "\t\t# Depois, ela vai retornar uma matriz com as features de cada frame de um único áudio, onde cada linha \n",
    "\t\t# é uma frame e cada coluna é uma feature.\n",
    "\n",
    "\t\t# PRIMEIRO, VOU CRIAR A MATRIZ QUE VAI CONTER AS FEATURES DE CADA JANELA\n",
    "\t\t# CADA LINHA E UMA JANELA E CADA COLUNA E UMA FEATURE\n",
    "\t\tmatrizFeaturesAudio = []\n",
    "\t\t\n",
    "\t\t# DEPOIS, VOU FAZER O JANELAMENTO\n",
    "\t\tmatrizFramesAudio = self.fazerJanelamento(sinal, frameLength, overlapLength)\n",
    "\t\t\n",
    "\t\t# AGORA, PARA CADA JANELA, VOU EXTRAIR AS FEATURES E COLOCAR COMO UMA LINHA NOVA NA MATRIZ\n",
    "\t\tfor frameAtual in matrizFramesAudio:\n",
    "\t\t\tmatrizFeaturesAudio.append(self.extrairFeaturesUnicoFrame(frameAtual, freqAmostragem, frameLength))\n",
    "\t\t\n",
    "\t\t# RETORNO A MATRIZ DE FEATURES DESSE AUDIO\n",
    "\t\treturn matrizFeaturesAudio\n",
    "\n",
    "\tdef adicionarNomeArquivoEClasse(self, matrizFeaturesAudioAtual, nomeArquivo, classificacaoCorreta):\n",
    "\t\t#Função que coloca o nome do arquivo e a classificação correta na matriz de features de um áudio\n",
    "\t\t#Haverá uma matriz de dados que terá as seguintes colunas: nomeArquivo, ...features... e classificacaoCorreta. \n",
    "\t\t#Mas, a função implementada para gerar a matriz de features de um único áudio extrairFeaturesUnicoAudio \n",
    "\t\t#devolve uma matriz de features sem o nome do áudio e a classificação correta. Portanto, a função abaixo \n",
    "\t\t# apenas pega essa última matriz e coloca o nome do arquivo no começo e a classificação correta ao final. \n",
    "\t\t# Posteriormente, o resultado será agregado à matriz de dados citada em primeiro lugar.\n",
    "\n",
    "\t\t#ESSA FUNÇÃO RETORNA UM DATAFRAME PANDAS, NÃO UMA MATRIZ QUALQUER.\n",
    "\n",
    "\t\t#https://www.geeksforgeeks.org/python-pandas-dataframe-insert/\n",
    "\n",
    "\t\t# PRIMEIRO TRANSFORMO A MATRIZ NUM PANDAS DATAFRAME\n",
    "\t\tdataframeAudioAtual = pd.DataFrame(matrizFeaturesAudioAtual)\n",
    "\t\t\n",
    "\t\t# AGORA COLOCO A COLUNA DO NOME NO COMECO (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "\t\tdataframeAudioAtual.insert(0, \"nomeArquivo\", nomeArquivo, True)\n",
    "\t\t\n",
    "\t\t# AGORA COLOCO A COLUNA DA CLASSIFICACAO CORRETA NA ULTIMA POSICAO\n",
    "\t\tdataframeAudioAtual.insert(len(dataframeAudioAtual.columns), \"classificacaoCorreta\", classificacaoCorreta, True)\n",
    "\t\t\n",
    "\t\treturn dataframeAudioAtual\n",
    "\n",
    "\tdef verificarClassificacaoCorreta(self, nomeArquivo):\n",
    "\t\t#Função para verificar qual é a classificação correta de acordo com o nome do arquivo\n",
    "\t\t#Essa é bem básica. Em algum determinado momento eu vou precisar saber a classficação \n",
    "\t\t# correta de um determinado áudio. Eu só consigo saber isso pelo nome do arquivo. LEMBRANDO QUE \n",
    "\t\t# TODO O CÓDIGO ESCRITO AQUI SERVE PARA O BANCO DE DADOS SESA. Os arquivos são nomeados \n",
    "\t\t# como classe_contador.wav. Por exemplo: casual_000.wav, explosion_032.wav e gunshot_032.wav.\n",
    "\t\tarrayNome = nomeArquivo.split(\"_\")\n",
    "\t\treturn arrayNome[0]\n",
    "\n",
    "\tdef montarDataframeTodosOsAudios(self, diretorio, freqAmostragem, frameLength, overlapLength):\n",
    "\t\t# Função que passa por todos os áudios da pasta e vai montando o dataframe\n",
    "\t\t# Essa é função que une todas as outras. Ela vai passar por todos os áudios da pasta, \n",
    "\t\t# verificar qual é a classificação correta de cada áudio, extrair as features, gerar o \n",
    "\t\t# dataframe de features do áudio atual e agregar ao dataframe de todos os áudios.\n",
    "\t\n",
    "\t\t# CRIANDO O ARRAY COM O NOME DOS ARQUIVOS\n",
    "\t\tarrayNomeArquivos = os.listdir(diretorio)\n",
    "\t\t\n",
    "\t\t# PEGANDO O TOTAL DE ARQUIVOS NA PASTA APENAS PARA FINS DE PRINT\n",
    "\t\ttotalArquivosNaPasta = len(arrayNomeArquivos)\n",
    "\t\t\n",
    "\t\t# ABAIXO, VOU CRIAR O DATAFRAME DE TODOS OS AUDIOS\n",
    "\t\tdataframeGeral = pd.DataFrame()\n",
    "\n",
    "\t\t# VOU PASSAR POR TODOS OS AUDIOS DO DIRETORIO\n",
    "\t\tfor i, nomeArquivo in enumerate(arrayNomeArquivos):\n",
    "\t\t\t# PRINTANDO O PROGRESSO\n",
    "\t\t\tprint(\"Extraindo features do arquivo\", i+1, \"de\", totalArquivosNaPasta, \"-> \" + str(100*((i+1)/totalArquivosNaPasta)) + \"%\")\n",
    "\t\t\t\n",
    "\t\t\t# ABRO O AUDIO ATUAL COM O LIBROSA\n",
    "\t\t\taudioAtual, freqAmostragem = librosa.load(diretorio+nomeArquivo, sr=freqAmostragem, mono=True) \n",
    "\t\t\t\n",
    "\t\t\t# VERIFICAO QUAL E A CLASSIFICACAO CORRETA\n",
    "\t\t\tclasseAudioAtual = self.verificarClassificacaoCorreta(nomeArquivo)\n",
    "\t\t\t\n",
    "\t\t\t# MONTO A MATRIZ DE FEATUREA DE CADA FRAME DO AUDIO ATUAL (a funcao abaixo\n",
    "\t\t\t# devolve uma matriz normal e faz o janelamento em outra funcao tb)\n",
    "\t\t\tmatrizFeaturesAudioAtual = self.extrairFeaturesUnicoAudio(audioAtual, freqAmostragem, frameLength, overlapLength)\n",
    "\t\t\t\n",
    "\t\t\t# AGORA E HORA DE COLOCAR O NOME E A CLASSIFICACAO CORRETA NA MATRIZ\n",
    "\t\t\t# MAAAS, NA FUNCAO ABAIXO, O BICHO VIRA UM DATAFRAME PANDAS\n",
    "\t\t\tdataframeAudioAtual      = self.adicionarNomeArquivoEClasse(matrizFeaturesAudioAtual, nomeArquivo, classeAudioAtual)\n",
    "\t\t\t\n",
    "\t\t\t# CONCATENANDO O DATAFRAME DO AUDIO ATUAL AO DATAFRAME GERAL\n",
    "\t\t\tdataframeGeral = pd.concat([dataframeGeral, dataframeAudioAtual])\n",
    "\t\t\t\n",
    "\t\t# POR ULTIMO, RETORNO O DATAFRAME GERAL\n",
    "\t\treturn dataframeGeral\n",
    "\n",
    "\tdef escalonarFeatures(self, dataframeGeral):\n",
    "\t\t\n",
    "\t\t# Função para escalonar as features\n",
    "\t\t# Essa função recebe o dataframe geral, remove as primeira e última colunas (nome e classificação), \n",
    "\t\t# faz o escalonamento e depois coloca as colunas de nome e classificação de volta.\n",
    "\t\n",
    "\t\tprint(\"Escalonando features\")\n",
    "\t\t\n",
    "\t\t# COPIANDO AS COLUNAS DE NOME E CLASSIFICACAO\n",
    "\t\tcolunaArquivo       = dataframeGeral[\"nomeArquivo\"]\n",
    "\t\tcolunaClassificacao = dataframeGeral[\"classificacaoCorreta\"]\n",
    "\t\t\n",
    "\t\t# DELETANDO AS COLUNAS ARQUIVO E CLASSIFICACAO\n",
    "\t\tdataframeGeral = dataframeGeral.drop(['nomeArquivo', 'classificacaoCorreta'], axis=1)\n",
    "\t\t\n",
    "\t\t# ESCALONANDO\n",
    "\t\tdataframeGeral = pd.DataFrame(StandardScaler().fit_transform(dataframeGeral))\n",
    "\t\t\n",
    "\t\t# COM ESSA COISA DE TIRA E POE COLUNA, O PANDAS NAO SABE LINDAR COM OS INDEXES,\n",
    "\t\t# ABAIXO EU ESTOU RESETANDO TUDO\n",
    "\t\tcolunaArquivo.reset_index(inplace=True, drop=True)\n",
    "\t\tcolunaClassificacao.reset_index(inplace=True, drop=True)\n",
    "\t\tdataframeGeral.reset_index(inplace=True, drop=True)\n",
    "\t\t\n",
    "\t\t# ADICIONANDO AS COLUNAS QUE FORAM EXCLUIDAS (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "\t\tdataframeGeral.insert(0, \"nomeArquivo\", colunaArquivo, True)\n",
    "\t\tdataframeGeral.insert(len(dataframeGeral.columns), \"classificacaoCorreta\", colunaClassificacao, True)\n",
    "\t\t\n",
    "\t\treturn dataframeGeral\n",
    "\n",
    "\tdef reduzirDimensionalidade(self, dataframeGeral, nDimensoes):\n",
    "\t\n",
    "\t\t# Função que reduz a dimensionalidade do dataframe geral\n",
    "\t\t# Depois de escalonar, vamos reduzir a dimensionalidade utilizando PCA. \n",
    "\t\t# A ideia é fazer com que o CSV já saia pronto para ser usado, logo, a redução \n",
    "\t\t# de dimensionalidade deve vir nessa classe. Apesar disso, vou deixar o parâmetro \n",
    "\t\t# nDimensoes lá no construtor da classe, ai caso ele seja nulo eu pulo a parte da \n",
    "\t\t# redução de dimensionalidade e gero o CSV com todas as features.\n",
    "\n",
    "\t\tprint(\"Reduzindo a dimensionalidade\")\n",
    "\t\t\n",
    "\t\t# COPIANDO AS COLUNAS DE NOME E CLASSIFICACAO\n",
    "\t\tcolunaArquivo       = dataframeGeral[\"nomeArquivo\"]\n",
    "\t\tcolunaClassificacao = dataframeGeral[\"classificacaoCorreta\"]\n",
    "\t\t\n",
    "\t\t# DELETANDO AS COLUNAS ARQUIVO E CLASSIFICACAO\n",
    "\t\tdataframeGeral = dataframeGeral.drop(['nomeArquivo', 'classificacaoCorreta'], axis=1)\n",
    "\t\t\n",
    "\t\t# REDUZINDO A DIMENSIONALIDADE\n",
    "\t\tdataframeGeral = pd.DataFrame(PCA(n_components=nDimensoes).fit_transform(dataframeGeral))\n",
    "\t\t\n",
    "\t\t# COM ESSA COISA DE TIRA E POE COLUNA, O PANDAS NAO SABE LINDAR COM OS INDEXES,\n",
    "\t\t# ABAIXO EU ESTOU RESETANDO TUDO\n",
    "\t\tcolunaArquivo.reset_index(inplace=True, drop=True)\n",
    "\t\tcolunaClassificacao.reset_index(inplace=True, drop=True)\n",
    "\t\tdataframeGeral.reset_index(inplace=True, drop=True)\n",
    "\t\t\n",
    "\t\t# ADICIONANDO AS COLUNAS QUE FORAM EXCLUIDAS (posicaoNovaColuna, nomeNovaColuna, valorParaTodasAsLinhas)\n",
    "\t\tdataframeGeral.insert(0, \"nomeArquivo\", colunaArquivo, True)\n",
    "\t\tdataframeGeral.insert(len(dataframeGeral.columns), \"classificacaoCorreta\", colunaClassificacao, True)\n",
    "\t\t\n",
    "\t\treturn dataframeGeral\n",
    "\n",
    "\t# DEFINICAO DAS FUNCOES QUE REALMENTE EXTRAEM AS FEATURES -----------------------------------------------\n",
    "\n",
    "\tdef extrairRMS(self, sinal, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.rms(y=sinal, frame_length=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairCentroideEspectral(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.spectral_centroid(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairLarguraBanda(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.spectral_bandwidth(y=sinal, sr= freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairPlanicidade(self, sinal, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.spectral_flatness(y=sinal, n_fft=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairRolloff(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.spectral_rolloff(y=sinal, sr= freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairZCR(self, sinal, frameLength, overlapLength):\n",
    "\t\treturn librosa.feature.zero_crossing_rate(y=sinal, frame_length=frameLength, hop_length=overlapLength)\n",
    "\n",
    "\tdef extrairMatrizMFCC(self, sinal, freqAmostragem):\n",
    "\t\treturn librosa.feature.mfcc(y=sinal, sr=freqAmostragem)\n",
    "\n",
    "\tdef extrairMFCCs(self, matrizMFCC):\n",
    "\t\t\n",
    "\t\tarrayMFCCs = []\n",
    "\t\t\n",
    "\t\tfor linha in matrizMFCC:\n",
    "\t\t\tarrayMFCCs.append(np.mean(linha))\n",
    "\t\t\t\n",
    "\t\treturn arrayMFCCs\n",
    "\n",
    "\tdef extrairDeltas(self, matrizMFCC):\n",
    "\t\tmatrizDelta = librosa.feature.delta(matrizMFCC, order=1)\n",
    "\n",
    "\t\tarrayDelta = []\n",
    "\n",
    "\t\tfor linha in matrizDelta:\n",
    "\t\t\tarrayDelta.append(np.mean(linha))\n",
    "\n",
    "\t\treturn arrayDelta\n",
    "\n",
    "\tdef extrairDeltaDeltas(self, matrizMFCC):\n",
    "\t\tmatrizDeltaDelta = librosa.feature.delta(matrizMFCC, order=2)\n",
    "\n",
    "\t\tarrayDeltaDelta = []\n",
    "\n",
    "\t\tfor linha in matrizDeltaDelta:\n",
    "\t\t\tarrayDeltaDelta.append(np.mean(linha))\n",
    "\n",
    "\t\treturn arrayDeltaDelta\n",
    "\n",
    "\tdef extrairMelEspectrograma(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\t\n",
    "\t\tmatrizMelEspectrograma = librosa.feature.melspectrogram(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\t\t\n",
    "\t\tarrayMelEspectrograma = []\n",
    "\t\t\n",
    "\t\tfor coluna in matrizMelEspectrograma.T:\n",
    "\t\t\tarrayMelEspectrograma.append(np.mean(coluna))\n",
    "\t\t\n",
    "\t\treturn arrayMelEspectrograma\n",
    "\n",
    "\tdef extrairCromagramas(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\t\n",
    "\t\tmatrizCromagramas = librosa.feature.chroma_stft(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\t\t\n",
    "\t\tarrayCromagramas = []\n",
    "\t\t\n",
    "\t\tfor linha in matrizCromagramas:\n",
    "\t\t\tarrayCromagramas.append(np.mean(linha))\n",
    "\t\t\n",
    "\t\treturn arrayCromagramas\n",
    "\n",
    "\tdef extrairCromagramasQ(self, sinal, freqAmostragem):\n",
    "\t\t\n",
    "\t\tmatrizCromagramasQ = librosa.feature.chroma_cqt(y=sinal, sr=freqAmostragem)\n",
    "\t\t\n",
    "\t\tarrayCromagramasQ = []\n",
    "\t\t\n",
    "\t\tfor linha in matrizCromagramasQ:\n",
    "\t\t\tarrayCromagramasQ.append(np.mean(linha))\n",
    "\t\t\n",
    "\t\treturn arrayCromagramasQ\n",
    "\n",
    "\tdef extrairCromaCENSs(self, sinal, freqAmostragem):\n",
    "\t\t\n",
    "\t\tmatrizCromaCENSs = librosa.feature.chroma_cens(y=sinal, sr=freqAmostragem)\n",
    "\t\t\n",
    "\t\tarrayCromaCENSs = []\n",
    "\t\t\n",
    "\t\tfor linha in matrizCromaCENSs:\n",
    "\t\t\tarrayCromaCENSs.append(np.mean(linha))\n",
    "\t\t\n",
    "\t\treturn arrayCromaCENSs\n",
    "\n",
    "\tdef extrairContrastes(self, sinal, freqAmostragem, frameLength, overlapLength):\n",
    "\t\t\n",
    "\t\tmatrizContrastes = librosa.feature.spectral_contrast(y=sinal, sr=freqAmostragem, n_fft=frameLength, hop_length=overlapLength)\n",
    "\t\t\n",
    "\t\tarrayConstrastes = []\n",
    "\t\t\n",
    "\t\tfor linha in matrizContrastes:\n",
    "\t\t\tarrayConstrastes.append(np.mean(linha))\n",
    "\t\t\n",
    "\t\treturn arrayConstrastes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
