{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESPECIFICANDO QUAL DATASET SERÁ UTILIZADO\n",
    "bits = 16\n",
    "amostragem = 48\n",
    "\n",
    "# CRIANDO O CAMINHO PARA O CSV\n",
    "caminhoCSV = \"../datasets/features_\" + str(bits) + \"bits_\" + str(amostragem) + \"k.csv\"\n",
    "\n",
    "# ABRINDO O CSV COMO UM NUMPY ARRAY\n",
    "datasetOriginal = numpy.genfromtxt(caminhoCSV, delimiter=\",\")\n",
    "\n",
    "# DELETANDO A PRIMEIRA LINHA (CABECALHO) E A SEGUNDA COLUNA (NOMES DOS ARQUIVOS)\n",
    "datasetOriginal = numpy.delete(datasetOriginal, 0, 0)\n",
    "datasetOriginal = numpy.delete(datasetOriginal, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] PASTA:\t\t 1.0\n",
      "[1] MFCC0:\t\t -226.54393747844244\n",
      "[2] MFCC1:\t\t 140.98918142663464\n",
      "[3] MFCC2:\t\t -43.09198176972208\n",
      "[4] MFCC3:\t\t 54.58026594224066\n",
      "[5] MFCC4:\t\t -21.203846110848318\n",
      "[6] MFCC5:\t\t 14.664003033541944\n",
      "[7] MFCC6:\t\t -12.983213525002245\n",
      "[8] MFCC7:\t\t 15.706151689337831\n",
      "[9] MFCC8:\t\t -10.612478133380957\n",
      "[10] MFCC9:\t\t 10.136786853547216\n",
      "[11] MFCC10:\t\t -1.6929493287185677\n",
      "[12] MFCC11:\t\t 2.862301608037136\n",
      "[13] MFCC12:\t\t -4.607714719751819\n",
      "[14] RMS:\t\t 0.03107336\n",
      "[15] CENTROIDE:\t\t 3517.7396779161822\n",
      "[16] LARGURA:\t\t 3714.066105297125\n",
      "[17] PLANICIDADE:\t 0.00586569\n",
      "[18] ROLLOFF:\t\t 7115.587599734043\n",
      "[19] ZCR:\t\t 0.08398956948138298\n",
      "[20] ASSIMETRIA:\t 0.013166787102818489\n",
      "[21] CURTOSE:\t\t 0.8388823726512014\n",
      "[22] VARIANCIA:\t\t 0.0009904432\n",
      "[23] CLASSIFICACAO:\t 7.0\n"
     ]
    }
   ],
   "source": [
    "# VISUALIZANDO ALGUM DADO\n",
    "dadoAleatorio = 100\n",
    "\n",
    "print(\"[0] PASTA:\\t\\t\", datasetOriginal[dadoAleatorio][0])\n",
    "print(\"[1] MFCC0:\\t\\t\", datasetOriginal[dadoAleatorio][1])\n",
    "print(\"[2] MFCC1:\\t\\t\", datasetOriginal[dadoAleatorio][2])\n",
    "print(\"[3] MFCC2:\\t\\t\", datasetOriginal[dadoAleatorio][3])\n",
    "print(\"[4] MFCC3:\\t\\t\", datasetOriginal[dadoAleatorio][4])\n",
    "print(\"[5] MFCC4:\\t\\t\", datasetOriginal[dadoAleatorio][5])\n",
    "print(\"[6] MFCC5:\\t\\t\", datasetOriginal[dadoAleatorio][6])\n",
    "print(\"[7] MFCC6:\\t\\t\", datasetOriginal[dadoAleatorio][7])\n",
    "print(\"[8] MFCC7:\\t\\t\", datasetOriginal[dadoAleatorio][8])\n",
    "print(\"[9] MFCC8:\\t\\t\", datasetOriginal[dadoAleatorio][9])\n",
    "print(\"[10] MFCC9:\\t\\t\", datasetOriginal[dadoAleatorio][10])\n",
    "print(\"[11] MFCC10:\\t\\t\", datasetOriginal[dadoAleatorio][11])\n",
    "print(\"[12] MFCC11:\\t\\t\", datasetOriginal[dadoAleatorio][12])\n",
    "print(\"[13] MFCC12:\\t\\t\", datasetOriginal[dadoAleatorio][13])\n",
    "print(\"[14] RMS:\\t\\t\", datasetOriginal[dadoAleatorio][14])\n",
    "print(\"[15] CENTROIDE:\\t\\t\", datasetOriginal[dadoAleatorio][15])\n",
    "print(\"[16] LARGURA:\\t\\t\", datasetOriginal[dadoAleatorio][16])\n",
    "print(\"[17] PLANICIDADE:\\t\", datasetOriginal[dadoAleatorio][17])\n",
    "print(\"[18] ROLLOFF:\\t\\t\", datasetOriginal[dadoAleatorio][18])\n",
    "print(\"[19] ZCR:\\t\\t\", datasetOriginal[dadoAleatorio][19])\n",
    "print(\"[20] ASSIMETRIA:\\t\", datasetOriginal[dadoAleatorio][20])\n",
    "print(\"[21] CURTOSE:\\t\\t\", datasetOriginal[dadoAleatorio][21])\n",
    "print(\"[22] VARIANCIA:\\t\\t\", datasetOriginal[dadoAleatorio][22])\n",
    "print(\"[23] CLASSIFICACAO:\\t\", datasetOriginal[dadoAleatorio][23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFold(dataset):\n",
    "\n",
    "    # ESSA FUNCAO RETORNARA UMA MATRIZ COM AS SEGUINTES DIMENSOES\n",
    "    # matriz[iteracaoKFold][colunaDeTreinoOuTeste][dadoPuro][feature]\n",
    "    # iteracaoKFold -> vai de 0 a 9 e representa as 10 iteracoes do KFold\n",
    "    # colunaDeTreinoOuTeste -> vai pegar os dados de treinamento (0) ou os de teste (1)\n",
    "    # dadoPuro -> dado com varias features, a pasta e a classificacao correta\n",
    "    # feature -> seleciona uma das 24 features do dado\n",
    "    \n",
    "    matriz = []\n",
    "    \n",
    "    for pastaTeste in range(1,11):\n",
    "\n",
    "        rodada = []\n",
    "        xTrain = []\n",
    "        xTest  = []\n",
    "\n",
    "        for dado in dataset:\n",
    "            if int(dado[0]) == pastaTeste:\n",
    "                xTest.append(dado)\n",
    "            else:\n",
    "                xTrain.append(dado)\n",
    "        \n",
    "        rodada.append(xTrain)\n",
    "        rodada.append(xTest)\n",
    "        \n",
    "        matriz.append(rodada)\n",
    "    \n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearranjarDataset(dataset, datasetOriginal, featureAtual, i):\n",
    "    \n",
    "    # ESSA FUNCAO ADICIONA UMA NOVA FEATURE AO DATASET\n",
    "    \n",
    "    # REMOVENDO A COLUNA DE CLASSIFICACAO\n",
    "    dataset = dataset[:,0:-1]\n",
    "\n",
    "    # SE NAO FOR A PRIMEIRA ITERACAO, EXCLUIR A ULTIMA FEATURE\n",
    "    if(i != 0):\n",
    "        dataset = dataset[:,0:-1]\n",
    "\n",
    "    # ADICIONANDO A FEATURE ATUAL NO DATASET\n",
    "    colunaNova = datasetOriginal[:,featureAtual]\n",
    "    dataset = numpy.column_stack((dataset, colunaNova))\n",
    "\n",
    "    # ADICIONANDO NOVAMENTE A CLASSIFICACAO\n",
    "    colunaNova = datasetOriginal[:,23]\n",
    "    dataset = numpy.column_stack((dataset, colunaNova))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novaMelhorFeature(dataset, datasetOriginal, melhorFeature, featuresRestantes):\n",
    "    \n",
    "    # ESSA FUNCAO SERVE PARA QUE, DEPOIS DE DEFINIDA A NOVA FEATURE QUE VAI ENTRAR NO DATASET PERMANENTEMENTE, \n",
    "    # REARRANJAR O DATASET E REMOVER ESSA FEATURE DO ARRAY DE FEATURES RESTANTES\n",
    "    \n",
    "    # REMOVENDO A COLUNA DE CLASSIFICACAO E A ULTIMA FEATURE UTILIZADA\n",
    "    dataset = dataset[:,0:-2]\n",
    "\n",
    "    # ADICIONANDO A FEATURE NOVA NO DATASET\n",
    "    colunaNova = datasetOriginal[:,melhorFeature]\n",
    "    dataset = numpy.column_stack((dataset, colunaNova))\n",
    "\n",
    "    # ADICIONANDO NOVAMENTE A CLASSIFICACAO\n",
    "    colunaNova = datasetOriginal[:,23]\n",
    "    dataset = numpy.column_stack((dataset, colunaNova))\n",
    "    \n",
    "    # REMOVENDO DO ARRAY DE FEATURES RESTANTES\n",
    "    indexPraRemover = numpy.where(featuresRestantes == melhorFeature)\n",
    "    featuresRestantes = numpy.delete(featuresRestantes, indexPraRemover)\n",
    "        \n",
    "    return dataset, featuresRestantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTENDO O DATASET\n",
    "dataset = datasetOriginal\n",
    "\n",
    "# CRIANDO O CLASSIFICADOR\n",
    "knn = KNeighborsClassifier(7)\n",
    "\n",
    "# PARA CADA ITERACAO DO KFOLD\n",
    "arrayAcuraciasKNN = []\n",
    "matrizKFold = kFold(dataset)\n",
    "for iteracaoKFold in matrizKFold:\n",
    "\n",
    "    # SEPARANDO OS DADOS DE TREINAMENTO E TESTE E JÁ EXCLUINDO A COLUNA 0 (pasta)\n",
    "    dadosTreino = numpy.delete(iteracaoKFold[0], 0, axis=1)\n",
    "    dadosTeste  = numpy.delete(iteracaoKFold[1], 0, axis=1)\n",
    "\n",
    "    # SEPARANDO O QUE E X E Y\n",
    "    xTrain = numpy.delete(dadosTreino, 22, axis=1) # exclui a coluna do target\n",
    "    xTest  = numpy.delete(dadosTeste, 22, axis=1) # exclui a coluna do target\n",
    "    yTrain = numpy.delete(dadosTreino, numpy.s_[0:22], axis=1).ravel() # exclui as colunas menos a 22\n",
    "    yTest  = numpy.delete(dadosTeste, numpy.s_[0:22], axis=1).ravel() # exclui as colunas menos a 22\n",
    "\n",
    "    # TREINANDO O CLASSIFICADOR (ignorando a pasta e usando a coluna 23 como target)\n",
    "    knn = knn.fit(xTrain, yTrain)\n",
    "\n",
    "    # PREDIZENDO\n",
    "    yKNN = knn.predict(xTest)\n",
    "\n",
    "    # VERIFICANDO A ACURACIA\n",
    "    arrayAcuraciasKNN.append(accuracy_score(yTest, yKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3863298662704309,\n",
       " 0.29651162790697677,\n",
       " 0.34206896551724136,\n",
       " 0.4139240506329114,\n",
       " 0.44565217391304346,\n",
       " 0.35313001605136435,\n",
       " 0.32445141065830724,\n",
       " 0.3811881188118812,\n",
       " 0.46266233766233766,\n",
       " 0.3783359497645212]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayAcuraciasKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('file.txt','w') \n",
    "\n",
    "# O DATASET COMECA SO COM A COLUNA 0 (PASTA) E A 23 (CLASSIFICACAO)\n",
    "dataset = numpy.delete(datasetOriginal, numpy.s_[1:-1], axis=1)\n",
    "\n",
    "# ARRAY DE FEATURES QUE FALTAM, 0 E A PASTA E 23 E A CLASSIFICACAO, POR ISSO NAO ENTRAM\n",
    "featuresRestantes = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22])\n",
    "\n",
    "# ENQUANTO HOUVEREM FEATURES A SEREM TESTADAS\n",
    "while(len(featuresRestantes) != 0):\n",
    "    \n",
    "    file.write(\"\\n\\n\\nNOVA ITERAÇÃO DO WHILE\")\n",
    "    file.write(\"\\n\\nFeatures restantes: \" + str(featuresRestantes))\n",
    "    \n",
    "    melhorAcuraciaKNN = 0\n",
    "    melhorFeatureKNN = 1\n",
    "    \n",
    "    # PARA CADA FEATURE RESTANTE EU A ADICIONO NAS QUE JA ESTAO SENDO UTILIZADAS\n",
    "    for i, featureAtual in enumerate(featuresRestantes):\n",
    "        \n",
    "        file.write(\"\\n\\nTestando a feature \" + str(featureAtual))\n",
    "        \n",
    "        # REARRANJO O DATASET COM A FEATURE ATUAL\n",
    "        dataset = rearranjarDataset(dataset, datasetOriginal, featureAtual, i)\n",
    "        \n",
    "        # AGORA QUE JA TENHO UM DATASET COM AS FEATURES DA VEZ, TENHO QUE TESTAR OS CLASSIFICADORES\n",
    "        knn = KNeighborsClassifier(7)\n",
    "        arrayAcuraciasKNN = []\n",
    "        \n",
    "        # PARA CADA ITERACAO DO KFOLD\n",
    "        matrizKFold = kFold(dataset)\n",
    "        for iteracaoKFold in matrizKFold:\n",
    "\n",
    "            # SEPARANDO OS DADOS DE TREINAMENTO E TESTE E JÁ EXCLUINDO A COLUNA 0 (pasta)\n",
    "            dadosTreino = numpy.delete(iteracaoKFold[0], 0, axis=1)\n",
    "            dadosTeste  = numpy.delete(iteracaoKFold[1], 0, axis=1)\n",
    "\n",
    "            # SEPARANDO O QUE E X E Y\n",
    "            xTrain = numpy.delete(dadosTreino, dadosTreino.shape[1] - 1, axis=1) # exclui a coluna do target\n",
    "            xTest  = numpy.delete(dadosTeste, dadosTeste.shape[1] - 1, axis=1) # exclui a coluna do target\n",
    "            yTrain = numpy.delete(dadosTreino, numpy.s_[0:dadosTreino.shape[1] - 1], axis=1).ravel() # exclui as colunas menos a 22\n",
    "            yTest  = numpy.delete(dadosTeste, numpy.s_[0:dadosTeste.shape[1] - 1], axis=1).ravel() # exclui as colunas menos a 22\n",
    "\n",
    "            # TREINANDO O CLASSIFICADOR (ignorando a pasta e usando a coluna 23 como target)\n",
    "            knn = knn.fit(xTrain, yTrain)\n",
    "\n",
    "            # PREDIZENDO\n",
    "            yKNN = knn.predict(xTest)\n",
    "\n",
    "            # VERIFICANDO A ACURACIA\n",
    "            arrayAcuraciasKNN.append(accuracy_score(yTest, yKNN))\n",
    "            \n",
    "        file.write(\"\\nA média das acurácias no KFold é \" + str(numpy.mean(arrayAcuraciasKNN)))\n",
    "        file.write(\"\\nA melhor acurácia até agora tinha sido \" + str(melhorAcuraciaKNN))\n",
    "        \n",
    "        # AGORA JA TENHO TODAS AS ACURACIAS DO KFOLD, VOU TIRAR A MEDIA \n",
    "        # E VER SE COM ESSA FEATURE O RESULTADO FOI BOM\n",
    "        if numpy.mean(arrayAcuraciasKNN) > melhorAcuraciaKNN:\n",
    "            file.write(\"\\nNova melhor feature identificada!\")\n",
    "            melhorAcuraciaKNN = numpy.mean(arrayAcuraciasKNN)\n",
    "            melhorFeatureKNN = featureAtual\n",
    "            file.write(\"\\nMelhor feature: \" + str(melhorFeatureKNN) + \". Melhor acurácia: \" + str(melhorAcuraciaKNN))\n",
    "            \n",
    "    # DEPOIS QUE ACABAR, EU REMOVO A MELHOR FEATURE DAS FEATURES RESTANTES E COLOCO ELA FIXA NO DATASET\n",
    "    file.write(\"\\n\\nTerminou o while. A melhor feature foi a \" + str(melhorFeatureKNN) + \". Colocando-a fixa no dataset.\")\n",
    "    dataset, featuresRestantes = novaMelhorFeature(dataset, datasetOriginal, melhorFeatureKNN, featuresRestantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
